{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7b1da9b-f49a-42d5-a911-2a730512770f",
   "metadata": {},
   "source": [
    "# Simple CLM Dataset Search Agent with FireLog\n",
    "\n",
    "This notebook demonstrates a basic agent that can:\n",
    "1. Search for datasets based on topics\n",
    "2. Answer questions about dataset metadata\n",
    "3. Maintain conversation history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7341bb20-00e2-482d-b26a-06f174cfcea4",
   "metadata": {},
   "source": [
    "## SETUP (One-time)\n",
    "\n",
    "Run this in your terminal:\n",
    "```bash\n",
    "logfire auth\n",
    "```\n",
    "\n",
    "This opens a browser to authenticate and saves your credentials. You only need to do this once.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a873f319-76a7-4269-a3cd-d6f2e2a6253d",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6421ab-5386-448c-a951-14b82191cac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in /home/jovyan/.local/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (8.1.7)\n",
      "Requirement already satisfied: pydantic-ai in /home/jovyan/.local/lib/python3.10/site-packages (1.25.1)\n",
      "Requirement already satisfied: fastmcp in /home/jovyan/.local/lib/python3.10/site-packages (2.13.1)\n",
      "Requirement already satisfied: openai in /home/jovyan/.local/lib/python3.10/site-packages (2.8.1)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
      "Requirement already satisfied: logfire in /home/jovyan/.local/lib/python3.10/site-packages (4.15.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (8.37.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: pydantic-ai-slim==1.25.1 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.25.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.3.0)\n",
      "Requirement already satisfied: genai-prices>=0.0.40 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.0.47)\n",
      "Requirement already satisfied: griffe>=1.3.2 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.15.0)\n",
      "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.28.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.38.0)\n",
      "Requirement already satisfied: pydantic-graph==1.25.1 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.25.1)\n",
      "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (2.12.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.4.2)\n",
      "Requirement already satisfied: pydantic-evals==1.25.1 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.25.1)\n",
      "Requirement already satisfied: mistralai>=1.9.10 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.9.11)\n",
      "Requirement already satisfied: starlette>=0.45.3 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.50.0)\n",
      "Requirement already satisfied: temporalio==1.19.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.19.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.5 in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.36.0)\n",
      "Requirement already satisfied: ag-ui-protocol>=0.1.8 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.1.10)\n",
      "Requirement already satisfied: anthropic>=0.75.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.75.0)\n",
      "Requirement already satisfied: google-auth>=2.36.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (2.43.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (2.32.5)\n",
      "Requirement already satisfied: groq>=0.25.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.36.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (9.1.2)\n",
      "Requirement already satisfied: boto3>=1.40.14 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.42.0)\n",
      "Requirement already satisfied: google-genai>=1.51.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.52.0)\n",
      "Requirement already satisfied: argcomplete>=3.5.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (3.6.3)\n",
      "Requirement already satisfied: prompt-toolkit>=3 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (3.0.52)\n",
      "Requirement already satisfied: pyperclip>=1.9.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.11.0)\n",
      "Requirement already satisfied: rich>=13 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (14.2.0)\n",
      "Requirement already satisfied: mcp>=1.18.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.22.0)\n",
      "Requirement already satisfied: cohere>=5.18.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (5.20.0)\n",
      "Requirement already satisfied: anyio>=0 in /usr/local/lib/python3.10/dist-packages (from pydantic-evals==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (4.11.0)\n",
      "Requirement already satisfied: logfire-api>=3.14.1 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-evals==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (4.15.1)\n",
      "Requirement already satisfied: pyyaml>=6.0.2 in /usr/local/lib/python3.10/dist-packages (from pydantic-evals==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (6.0.3)\n",
      "Requirement already satisfied: nexus-rpc==1.1.0 in /home/jovyan/.local/lib/python3.10/site-packages (from temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.1.0)\n",
      "Requirement already satisfied: protobuf<7.0.0,>=3.20 in /home/jovyan/.local/lib/python3.10/site-packages (from temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (6.33.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: types-protobuf>=3.20 in /home/jovyan/.local/lib/python3.10/site-packages (from temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (6.32.1.20251105)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (4.15.0)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.33.5->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.33.5->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (2025.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.33.5->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (25.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.33.5->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.33.5->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.2.0)\n",
      "Requirement already satisfied: aiohttp in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (3.13.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.8.2->temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.17.0)\n",
      "Requirement already satisfied: authlib>=1.6.5 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (1.6.5)\n",
      "Requirement already satisfied: cyclopts>=4.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (4.3.0)\n",
      "Requirement already satisfied: jsonschema-path>=0.3.4 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (0.3.4)\n",
      "Requirement already satisfied: openapi-pydantic>=0.5.1 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (0.5.1)\n",
      "Requirement already satisfied: platformdirs>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from fastmcp) (4.5.0)\n",
      "Requirement already satisfied: py-key-value-aio<0.3.0,>=0.2.8 in /home/jovyan/.local/lib/python3.10/site-packages (from py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (0.2.8)\n",
      "Requirement already satisfied: uvicorn>=0.35 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (0.38.0)\n",
      "Requirement already satisfied: websockets>=15.0.1 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (15.0.1)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /home/jovyan/.local/lib/python3.10/site-packages (from mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.4.0)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.10/dist-packages (from mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /home/jovyan/.local/lib/python3.10/site-packages (from mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (2.12.0)\n",
      "Requirement already satisfied: pyjwt>=2.10.1 in /home/jovyan/.local/lib/python3.10/site-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (2.10.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/jovyan/.local/lib/python3.10/site-packages (from mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /home/jovyan/.local/lib/python3.10/site-packages (from mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (3.0.3)\n",
      "Requirement already satisfied: beartype>=0.22.2 in /home/jovyan/.local/lib/python3.10/site-packages (from py-key-value-aio<0.3.0,>=0.2.8->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (0.22.7)\n",
      "Requirement already satisfied: py-key-value-shared==0.2.8 in /home/jovyan/.local/lib/python3.10/site-packages (from py-key-value-aio<0.3.0,>=0.2.8->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (0.2.8)\n",
      "Requirement already satisfied: diskcache>=5.6.0 in /home/jovyan/.local/lib/python3.10/site-packages (from py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (5.6.3)\n",
      "Requirement already satisfied: pathvalidate>=3.3.1 in /home/jovyan/.local/lib/python3.10/site-packages (from py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (3.3.1)\n",
      "Requirement already satisfied: cachetools>=6.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (6.2.2)\n",
      "Requirement already satisfied: keyring>=25.6.0 in /home/jovyan/.local/lib/python3.10/site-packages (from py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (25.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (2.41.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/jovyan/.local/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/jovyan/.local/lib/python3.10/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio>=0->pydantic-evals==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27->pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27->pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27->pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.16.0)\n",
      "Requirement already satisfied: executing>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from logfire) (2.2.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<1.39.0,>=1.35.0 in /home/jovyan/.local/lib/python3.10/site-packages (from logfire) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation>=0.41b0 in /home/jovyan/.local/lib/python3.10/site-packages (from logfire) (0.59b0)\n",
      "Requirement already satisfied: opentelemetry-sdk<1.39.0,>=1.35.0 in /home/jovyan/.local/lib/python3.10/site-packages (from logfire) (1.38.0)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from logfire) (2.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<1.39.0,>=1.35.0->logfire) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<1.39.0,>=1.35.0->logfire) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.38.0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<1.39.0,>=1.35.0->logfire) (1.38.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/jovyan/.local/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.28.0->pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-sdk<1.39.0,>=1.35.0->logfire) (0.59b0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (2.5.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.15 in /home/jovyan/.local/lib/python3.10/site-packages (from anthropic>=0.75.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.17.0)\n",
      "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from authlib>=1.6.5->fastmcp) (46.0.2)\n",
      "Requirement already satisfied: botocore<1.42.0,>=1.41.6 in /home/jovyan/.local/lib/python3.10/site-packages (from boto3>=1.40.14->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.41.6)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/jovyan/.local/lib/python3.10/site-packages (from boto3>=1.40.14->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in /home/jovyan/.local/lib/python3.10/site-packages (from boto3>=1.40.14->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.16.0)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /home/jovyan/.local/lib/python3.10/site-packages (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.12.1)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /home/jovyan/.local/lib/python3.10/site-packages (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.22.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (2.32.4.20250913)\n",
      "Requirement already satisfied: attrs>=23.1.0 in /usr/local/lib/python3.10/dist-packages (from cyclopts>=4.0.0->fastmcp) (25.4.0)\n",
      "Requirement already satisfied: rich-rst<2.0.0,>=1.3.1 in /home/jovyan/.local/lib/python3.10/site-packages (from cyclopts>=4.0.0->fastmcp) (1.3.2)\n",
      "Requirement already satisfied: docutils in /home/jovyan/.local/lib/python3.10/site-packages (from rich-rst<2.0.0,>=1.3.1->cyclopts>=4.0.0->fastmcp) (0.22.3)\n",
      "Requirement already satisfied: eval-type-backport>=0.2 in /home/jovyan/.local/lib/python3.10/site-packages (from genai-prices>=0.0.40->pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/jovyan/.local/lib/python3.10/site-packages (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/jovyan/.local/lib/python3.10/site-packages (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/jovyan/.local/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.6.1)\n",
      "Requirement already satisfied: colorama>=0.4 in /home/jovyan/.local/lib/python3.10/site-packages (from griffe>=1.3.2->pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.4.6)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit>=3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.20.0->mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.20.0->mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.20.0->mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.27.1)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in /home/jovyan/.local/lib/python3.10/site-packages (from jsonschema-path>=0.3.4->fastmcp) (0.4.4)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /home/jovyan/.local/lib/python3.10/site-packages (from keyring>=25.6.0->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (3.5.0)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /home/jovyan/.local/lib/python3.10/site-packages (from keyring>=25.6.0->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (0.9.0)\n",
      "Requirement already satisfied: jaraco.classes in /home/jovyan/.local/lib/python3.10/site-packages (from keyring>=25.6.0->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (3.4.0)\n",
      "Requirement already satisfied: jaraco.functools in /home/jovyan/.local/lib/python3.10/site-packages (from keyring>=25.6.0->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (4.3.0)\n",
      "Requirement already satisfied: jaraco.context in /home/jovyan/.local/lib/python3.10/site-packages (from keyring>=25.6.0->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (6.0.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-httpx>=0.42b0 in /home/jovyan/.local/lib/python3.10/site-packages (from logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.59b0)\n",
      "Requirement already satisfied: invoke<3.0.0,>=2.2.0 in /home/jovyan/.local/lib/python3.10/site-packages (from mistralai>=1.9.10->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (2.2.1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation>=0.41b0->logfire) (1.17.3)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.59b0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation-httpx>=0.42b0->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.59b0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic[email]>=2.11.7->fastmcp) (2.3.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp) (2.8.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cryptography->authlib>=1.6.5->fastmcp) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=2.0.0->cryptography->authlib>=1.6.5->fastmcp) (2.23)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jovyan/.local/lib/python3.10/site-packages (from rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jovyan/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.1.2)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.35->fastmcp) (8.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/jovyan/.local/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/jovyan/.local/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/jovyan/.local/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jovyan/.local/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jovyan/.local/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/jovyan/.local/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/jovyan/.local/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai) (1.22.0)\n",
      "Requirement already satisfied: more-itertools in /home/jovyan/.local/lib/python3.10/site-packages (from jaraco.classes->keyring>=25.6.0->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (10.8.0)\n",
      "Requirement already satisfied: backports.tarfile in /home/jovyan/.local/lib/python3.10/site-packages (from jaraco.context->keyring>=25.6.0->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv ipywidgets pydantic-ai fastmcp openai nest-asyncio logfire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a722b4-3a4b-468d-9116-8520f54e52eb",
   "metadata": {},
   "source": [
    "### Step 2: Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f534dd1-20e5-4965-bf57-d3cbe323e572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Logfire</span> project URL: <a href=\"https://logfire-us.pydantic.dev/stillsame2016/ndp-clm-agent\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; text-decoration: underline\">https://logfire-us.pydantic.dev/stillsame2016/ndp-clm-agent</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=499540;https://logfire-us.pydantic.dev/stillsame2016/ndp-clm-agent\u001b\\\u001b[4;36mhttps://logfire-us.pydantic.dev/stillsame2016/ndp-clm-agent\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Everything initialized and connected to Logfire cloud\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import nest_asyncio\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from fastmcp import Client\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from datetime import datetime\n",
    "import logfire\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Configure Logfire (sends to cloud)\n",
    "logfire.configure(service_name=\"ndp-clm-agent\")\n",
    "\n",
    "print(\"✓ Everything initialized and connected to Logfire cloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc49f3-a50d-4060-9243-d1d6b6af4179",
   "metadata": {},
   "source": [
    "### Step 3: API Keys and MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee5aca9-3edc-4458-8795-96e71b9108d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ NRP API key found - Using Qwen3\n",
      "✓ MCP client ready\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Choose your model: \"openai\" or \"nrp\"\n",
    "MODEL = \"nrp\"  # Change to \"nrp\" to use Qwen3\n",
    "\n",
    "# Check API keys based on model choice\n",
    "if MODEL == \"openai\":\n",
    "    openai_key = os.getenv('OPENAI_API_KEY')\n",
    "    if not openai_key:\n",
    "        print(\"⚠️ Warning: OPENAI_API_KEY not set!\")\n",
    "    else:\n",
    "        print(\"✓ OpenAI API key found - Using GPT-4o-mini\")\n",
    "elif MODEL == \"nrp\":\n",
    "    nrp_key = os.getenv('NRP_API_KEY')\n",
    "    if not nrp_key:\n",
    "        print(\"⚠️ Warning: NRP_API_KEY not set!\")\n",
    "    else:\n",
    "        print(\"✓ NRP API key found - Using Qwen3\")\n",
    "\n",
    "# Initialize MCP client\n",
    "mcp_client = Client(\"https://wenokn.fastmcp.app/mcp\")\n",
    "\n",
    "@dataclass\n",
    "class AgentContext:\n",
    "    current_dataset: Optional[dict] = None\n",
    "\n",
    "print(\"✓ MCP client ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ad519-9e0c-419f-b4c4-fc1c35c991dc",
   "metadata": {},
   "source": [
    "### Step 4: Create Agent with Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41672fb-1f9c-4480-95ea-091ca4528026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Agent created with automatic Logfire logging\n"
     ]
    }
   ],
   "source": [
    "def get_model_config(model_name: str = \"openai\"):\n",
    "    if model_name == \"nrp\":\n",
    "        os.environ['OPENAI_BASE_URL'] = 'https://ellm.nrp-nautilus.io/v1'\n",
    "        os.environ['OPENAI_API_KEY'] = os.getenv('NRP_API_KEY', '')\n",
    "        return 'openai:qwen3'\n",
    "    else:\n",
    "        if 'OPENAI_BASE_URL' in os.environ:\n",
    "            del os.environ['OPENAI_BASE_URL']\n",
    "        os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', '')\n",
    "        return 'openai:gpt-4o-mini'\n",
    "\n",
    "agent = Agent(\n",
    "    model=get_model_config(MODEL),\n",
    "    deps_type=AgentContext,\n",
    "    system_prompt=\"\"\"You are a helpful assistant that helps users find and learn about California Landscape Metrics datasets.\n",
    "\n",
    "You have access to a search_datasets tool that can find relevant datasets based on user queries.\n",
    "\n",
    "When a user asks about a topic:\n",
    "1. Use the search_datasets tool to find the most relevant dataset\n",
    "2. Present the top result with key information (title, description, units)\n",
    "3. Answer any follow-up questions about the dataset metadata\n",
    "\n",
    "Be concise and helpful!\"\"\"\n",
    ")\n",
    "\n",
    "@agent.tool\n",
    "async def search_datasets(\n",
    "    ctx: RunContext[AgentContext],\n",
    "    query: str,\n",
    "    top_k: int = 3\n",
    ") -> dict:\n",
    "    \"\"\"Search for datasets related to the query.\"\"\"\n",
    "    with logfire.span(\"search_datasets\", query=query, top_k=top_k):\n",
    "        async with mcp_client:\n",
    "            result = await mcp_client.call_tool(\n",
    "                \"search_datasets\",\n",
    "                {\"query\": query, \"top_k\": top_k}\n",
    "            )\n",
    "            \n",
    "            data = result.data\n",
    "            if data.get('success') and data.get('datasets'):\n",
    "                best_dataset = data['datasets'][0]\n",
    "                ctx.deps.current_dataset = best_dataset\n",
    "                \n",
    "                logfire.info(\"dataset_found\", dataset_title=best_dataset.get('title'), query=query)\n",
    "                \n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'top_dataset': best_dataset,\n",
    "                    'alternatives': data['datasets'][1:] if len(data['datasets']) > 1 else [],\n",
    "                    'message': f\"Found: {best_dataset['title']}\"\n",
    "                }\n",
    "            else:\n",
    "                logfire.warning(\"no_datasets_found\", query=query)\n",
    "                return {\n",
    "                    'success': False,\n",
    "                    'message': 'No datasets found',\n",
    "                    'error': data.get('error', 'Unknown error')\n",
    "                }\n",
    "\n",
    "print(\"✓ Agent created with automatic Logfire logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd49b424-bc46-4b6e-9e86-bc3ca6cf43e2",
   "metadata": {},
   "source": [
    "### Step 5: Conversational Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b751ca-3712-49f2-b7d4-b5ce6488a078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05:51:27.110 session_started\n",
      "✓ Conversational agent ready with nrp\n"
     ]
    }
   ],
   "source": [
    "class ConversationalAgent:\n",
    "    def __init__(self, agent, model_name=\"openai\"):\n",
    "        self.agent = agent\n",
    "        self.model_name = model_name\n",
    "        self.history = []\n",
    "        # NRP Qwen3 needs longer timeout\n",
    "        self.default_timeout = 180 if model_name == \"nrp\" else 60\n",
    "        \n",
    "        logfire.info(\"session_started\", model_name=model_name, timeout=self.default_timeout)\n",
    "    \n",
    "    async def ask(self, question: str, timeout: int = None) -> str:\n",
    "        if timeout is None:\n",
    "            timeout = self.default_timeout\n",
    "        \n",
    "        with logfire.span(\"ask_question\", question=question[:100]):\n",
    "            if self.history:\n",
    "                full_input = \"\\n\".join(self.history) + f\"\\nUser: {question}\"\n",
    "            else:\n",
    "                full_input = f\"User: {question}\"\n",
    "            \n",
    "            try:\n",
    "                result = await asyncio.wait_for(\n",
    "                    self.agent.run(full_input, deps=AgentContext()),\n",
    "                    timeout=timeout\n",
    "                )\n",
    "                response = result.output if hasattr(result, 'output') else str(result)\n",
    "                \n",
    "                self.history.append(f\"User: {question}\")\n",
    "                self.history.append(f\"Assistant: {response}\")\n",
    "                \n",
    "                logfire.info(\"response_generated\", response_length=len(response))\n",
    "                return response\n",
    "                \n",
    "            except asyncio.TimeoutError:\n",
    "                logfire.error(\"timeout\", timeout=timeout)\n",
    "                return f\"Error: Request timed out after {timeout} seconds.\"\n",
    "            except Exception as e:\n",
    "                logfire.error(\"error\", error_type=type(e).__name__, error_message=str(e), exc_info=True)\n",
    "                return f\"Error: {type(e).__name__}: {str(e)}\"\n",
    "    \n",
    "    def clear_history(self):\n",
    "        self.history = []\n",
    "        logfire.info(\"history_cleared\")\n",
    "\n",
    "conv_agent = ConversationalAgent(agent, model_name=MODEL)\n",
    "print(f\"✓ Conversational agent ready with {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a452fbfb-cb8a-43eb-a69f-89543dad05eb",
   "metadata": {},
   "source": [
    "### Step 6: Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c563b760-bcf1-42c2-9253-d1a1f2d7319c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Chat interface ready\n"
     ]
    }
   ],
   "source": [
    "class SimpleChatInterface:\n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "        self.messages = []\n",
    "        \n",
    "        self.output_area = widgets.VBox(\n",
    "            layout=widgets.Layout(border='1px solid #ddd', height='400px', overflow_y='auto', padding='10px', margin='10px 0')\n",
    "        )\n",
    "        \n",
    "        self.input_box = widgets.Textarea(\n",
    "            placeholder='Ask about datasets...',\n",
    "            layout=widgets.Layout(width='100%', height='80px')\n",
    "        )\n",
    "        \n",
    "        self.send_button = widgets.Button(description='Send', button_style='primary')\n",
    "        self.clear_button = widgets.Button(description='Clear', button_style='warning')\n",
    "        self.status_label = widgets.HTML(value=\"✅ Ready\")\n",
    "        \n",
    "        self.send_button.on_click(self.on_send)\n",
    "        self.clear_button.on_click(self.on_clear)\n",
    "        \n",
    "        button_row = widgets.HBox([self.send_button, self.clear_button, self.status_label])\n",
    "        self.interface = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>🤖 Dataset Search Agent</h3>\"),\n",
    "            self.output_area,\n",
    "            self.input_box,\n",
    "            button_row\n",
    "        ])\n",
    "        \n",
    "        # self.add_message(\"Welcome! Ask me about California Landscape Metrics datasets.\", \"system\")\n",
    "        # Welcome message\n",
    "        self.add_message(\n",
    "            \"Welcome! I can help you find California Landscape Metrics datasets.\\n\\n\"\n",
    "            \"Try asking:\\n\"\n",
    "            \"• Find datasets about carbon turnover\\n\"\n",
    "            \"• What datasets are available for burn probability?\\n\"\n",
    "            \"• Tell me about the units used in this dataset\\n\"\n",
    "            \"• What's the description of this dataset?\",\n",
    "            \"system\"\n",
    "        )\n",
    "    \n",
    "    def add_message(self, text, role=\"user\"):\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        colors = {\n",
    "            \"user\": (\"#007bff\", \"👤\", \"You\", \"#e7f3ff\"),\n",
    "            \"assistant\": (\"#28a745\", \"🤖\", \"Agent\", \"#e8f5e9\"),\n",
    "            \"system\": (\"#6c757d\", \"ℹ️\", \"System\", \"#f8f9fa\")\n",
    "        }\n",
    "        \n",
    "        color, icon, label, bg = colors.get(role, colors[\"system\"])\n",
    "        \n",
    "        message = widgets.HTML(\n",
    "            value=f\"\"\"<div style='margin: 10px 0; padding: 10px; background: {bg}; border-radius: 8px; border-left: 4px solid {color};'>\n",
    "                <div style='display: flex; justify-content: space-between; margin-bottom: 5px;'>\n",
    "                    <strong style='color: {color};'>{icon} {label}</strong>\n",
    "                    <span style='color: #999; font-size: 0.85em;'>{timestamp}</span>\n",
    "                </div>\n",
    "                <div style='white-space: pre-wrap;'>{text}</div>\n",
    "            </div>\"\"\"\n",
    "        )\n",
    "        \n",
    "        self.messages.append(message)\n",
    "        self.output_area.children = tuple(self.messages)\n",
    "    \n",
    "    def on_send(self, button):\n",
    "        question = self.input_box.value.strip()\n",
    "        if not question:\n",
    "            return\n",
    "        \n",
    "        self.add_message(question, \"user\")\n",
    "        self.input_box.value = \"\"\n",
    "        \n",
    "        self.send_button.disabled = True\n",
    "        self.input_box.disabled = True\n",
    "        self.status_label.value = \"<span style='color: orange;'>⏳ Thinking...</span>\"\n",
    "        \n",
    "        try:\n",
    "            response = asyncio.get_event_loop().run_until_complete(self.agent.ask(question))\n",
    "            self.add_message(response, \"assistant\")\n",
    "            self.status_label.value = \"<span style='color: green;'>✅ Ready</span>\"\n",
    "        except Exception as e:\n",
    "            self.add_message(f\"Error: {str(e)}\", \"system\")\n",
    "            self.status_label.value = \"<span style='color: red;'>❌ Error</span>\"\n",
    "        finally:\n",
    "            self.send_button.disabled = False\n",
    "            self.input_box.disabled = False\n",
    "    \n",
    "    def on_clear(self, button):\n",
    "        self.messages = []\n",
    "        self.agent.clear_history()\n",
    "        self.output_area.children = tuple(self.messages)\n",
    "        self.add_message(\"Chat cleared!\", \"system\")\n",
    "    \n",
    "    def display(self):\n",
    "        clear_output(wait=True)\n",
    "        display(self.interface)\n",
    "\n",
    "print(\"✓ Chat interface ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241167e5-9585-4734-b434-cc7f5d1cbfc9",
   "metadata": {},
   "source": [
    "### Step 7: Launch Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e657266a-bf01-4cf1-91aa-72fb9dda52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = SimpleChatInterface(conv_agent)\n",
    "chat.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998d9f08-b5ff-4f6b-b29f-1bb6cf2b8807",
   "metadata": {},
   "source": [
    "### Step 8: View Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46615898-f4c1-4f6c-83d9-d1a8a44486cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05:51:27.144 setup_complete\n",
      "✓ Setup complete!\n",
      "\n",
      "📊 View your logs at: https://logfire.pydantic.dev\n",
      "\n",
      "All CLM-MCP communications are automatically logged:\n",
      "  • Dataset searches\n",
      "  • Agent responses\n",
      "  • Errors and timeouts\n",
      "  • Performance metrics\n"
     ]
    }
   ],
   "source": [
    "logfire.info(\"setup_complete\", message=\"Visit https://logfire.pydantic.dev to view all logs\")\n",
    "print(\"✓ Setup complete!\")\n",
    "print(\"\\n📊 View your logs at: https://logfire.pydantic.dev\")\n",
    "print(\"\\nAll CLM-MCP communications are automatically logged:\")\n",
    "print(\"  • Dataset searches\")\n",
    "print(\"  • Agent responses\")\n",
    "print(\"  • Errors and timeouts\")\n",
    "print(\"  • Performance metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d1c37b-fd05-4a68-ba95-60d9d0579672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
