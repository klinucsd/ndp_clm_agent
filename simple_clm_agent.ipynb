{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Dataset Search Agent\n",
    "\n",
    "This notebook demonstrates a basic agent that can:\n",
    "1. Search for datasets based on topics\n",
    "2. Answer questions about dataset metadata\n",
    "3. Maintain conversation history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in /home/jovyan/.local/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (8.1.7)\n",
      "Requirement already satisfied: pydantic-ai in /home/jovyan/.local/lib/python3.10/site-packages (1.18.0)\n",
      "Requirement already satisfied: fastmcp in /home/jovyan/.local/lib/python3.10/site-packages (2.13.1)\n",
      "Requirement already satisfied: openai in /home/jovyan/.local/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (8.37.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: pydantic-ai-slim==1.18.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.18.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.3.0)\n",
      "Requirement already satisfied: genai-prices>=0.0.35 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.0.39)\n",
      "Requirement already satisfied: griffe>=1.3.2 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.15.0)\n",
      "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.28.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.38.0)\n",
      "Requirement already satisfied: pydantic-graph==1.18.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.18.0)\n",
      "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (2.12.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.4.2)\n",
      "Requirement already satisfied: anthropic>=0.70.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.73.0)\n",
      "Requirement already satisfied: cohere>=5.18.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (5.20.0)\n",
      "Requirement already satisfied: logfire>=3.14.1 in /home/jovyan/.local/lib/python3.10/site-packages (from logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (4.14.2)\n",
      "Requirement already satisfied: ag-ui-protocol>=0.1.8 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.1.10)\n",
      "Requirement already satisfied: starlette>=0.45.3 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.50.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.5 in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.1.4)\n",
      "Requirement already satisfied: google-genai>=1.50.1 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.50.1)\n",
      "Requirement already satisfied: pydantic-evals==1.18.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.18.0)\n",
      "Requirement already satisfied: mcp>=1.12.3 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.21.2)\n",
      "Requirement already satisfied: argcomplete>=3.5.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (3.6.3)\n",
      "Requirement already satisfied: prompt-toolkit>=3 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (3.0.52)\n",
      "Requirement already satisfied: pyperclip>=1.9.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.11.0)\n",
      "Requirement already satisfied: rich>=13 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (14.2.0)\n",
      "Requirement already satisfied: groq>=0.25.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.34.1)\n",
      "Requirement already satisfied: google-auth>=2.36.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (2.43.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (2.32.5)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (9.1.2)\n",
      "Requirement already satisfied: boto3>=1.40.14 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.40.75)\n",
      "Requirement already satisfied: mistralai>=1.9.10 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.9.11)\n",
      "Requirement already satisfied: temporalio==1.19.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.19.0)\n",
      "Requirement already satisfied: anyio>=0 in /usr/local/lib/python3.10/dist-packages (from pydantic-evals==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (4.11.0)\n",
      "Requirement already satisfied: logfire-api>=3.14.1 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-evals==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (4.14.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.2 in /usr/local/lib/python3.10/dist-packages (from pydantic-evals==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (6.0.3)\n",
      "Requirement already satisfied: nexus-rpc==1.1.0 in /home/jovyan/.local/lib/python3.10/site-packages (from temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.1.0)\n",
      "Requirement already satisfied: protobuf<7.0.0,>=3.20 in /home/jovyan/.local/lib/python3.10/site-packages (from temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (6.33.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: types-protobuf>=3.20 in /home/jovyan/.local/lib/python3.10/site-packages (from temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (6.32.1.20251105)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (4.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.8.2->temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.17.0)\n",
      "Requirement already satisfied: authlib>=1.6.5 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (1.6.5)\n",
      "Requirement already satisfied: cyclopts>=4.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (4.2.4)\n",
      "Requirement already satisfied: jsonschema-path>=0.3.4 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (0.3.4)\n",
      "Requirement already satisfied: openapi-pydantic>=0.5.1 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (0.5.1)\n",
      "Requirement already satisfied: platformdirs>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from fastmcp) (4.5.0)\n",
      "Requirement already satisfied: py-key-value-aio<0.3.0,>=0.2.8 in /home/jovyan/.local/lib/python3.10/site-packages (from py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (0.2.8)\n",
      "Requirement already satisfied: uvicorn>=0.35 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (0.38.0)\n",
      "Requirement already satisfied: websockets>=15.0.1 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (15.0.1)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /home/jovyan/.local/lib/python3.10/site-packages (from mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.4.0)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.10/dist-packages (from mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /home/jovyan/.local/lib/python3.10/site-packages (from mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (2.12.0)\n",
      "Requirement already satisfied: pyjwt>=2.10.1 in /home/jovyan/.local/lib/python3.10/site-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (2.10.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/jovyan/.local/lib/python3.10/site-packages (from mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /home/jovyan/.local/lib/python3.10/site-packages (from mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (3.0.3)\n",
      "Requirement already satisfied: beartype>=0.22.2 in /home/jovyan/.local/lib/python3.10/site-packages (from py-key-value-aio<0.3.0,>=0.2.8->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (0.22.5)\n",
      "Requirement already satisfied: py-key-value-shared==0.2.8 in /home/jovyan/.local/lib/python3.10/site-packages (from py-key-value-aio<0.3.0,>=0.2.8->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (0.2.8)\n",
      "Requirement already satisfied: diskcache>=5.6.0 in /home/jovyan/.local/lib/python3.10/site-packages (from py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (5.6.3)\n",
      "Requirement already satisfied: pathvalidate>=3.3.1 in /home/jovyan/.local/lib/python3.10/site-packages (from py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (3.3.1)\n",
      "Requirement already satisfied: keyring>=25.6.0 in /home/jovyan/.local/lib/python3.10/site-packages (from py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (25.7.0)\n",
      "Requirement already satisfied: cachetools>=6.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (6.2.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->pydantic-ai-slim==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->pydantic-ai-slim==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (2.41.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/jovyan/.local/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/jovyan/.local/lib/python3.10/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/jovyan/.local/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio>=0->pydantic-evals==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27->pydantic-ai-slim==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27->pydantic-ai-slim==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27->pydantic-ai-slim==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.16.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.15 in /home/jovyan/.local/lib/python3.10/site-packages (from anthropic>=0.70.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.17.0)\n",
      "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from authlib>=1.6.5->fastmcp) (46.0.2)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.75 in /home/jovyan/.local/lib/python3.10/site-packages (from boto3>=1.40.14->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.40.75)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/jovyan/.local/lib/python3.10/site-packages (from boto3>=1.40.14->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /home/jovyan/.local/lib/python3.10/site-packages (from boto3>=1.40.14->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.14.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.41.0,>=1.40.75->boto3>=1.40.14->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (2.5.0)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /home/jovyan/.local/lib/python3.10/site-packages (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.12.1)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /home/jovyan/.local/lib/python3.10/site-packages (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.22.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (2.32.4.20250913)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (3.4.3)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (25.0)\n",
      "Requirement already satisfied: shellingham in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.20.0)\n",
      "Requirement already satisfied: attrs>=23.1.0 in /usr/local/lib/python3.10/dist-packages (from cyclopts>=4.0.0->fastmcp) (25.4.0)\n",
      "Requirement already satisfied: rich-rst<2.0.0,>=1.3.1 in /home/jovyan/.local/lib/python3.10/site-packages (from cyclopts>=4.0.0->fastmcp) (1.3.2)\n",
      "Requirement already satisfied: tomli>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cyclopts>=4.0.0->fastmcp) (2.3.0)\n",
      "Requirement already satisfied: docutils in /home/jovyan/.local/lib/python3.10/site-packages (from rich-rst<2.0.0,>=1.3.1->cyclopts>=4.0.0->fastmcp) (0.22.3)\n",
      "Requirement already satisfied: eval-type-backport>=0.2 in /home/jovyan/.local/lib/python3.10/site-packages (from genai-prices>=0.0.35->pydantic-ai-slim==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/jovyan/.local/lib/python3.10/site-packages (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/jovyan/.local/lib/python3.10/site-packages (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/jovyan/.local/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.6.1)\n",
      "Requirement already satisfied: colorama>=0.4 in /home/jovyan/.local/lib/python3.10/site-packages (from griffe>=1.3.2->pydantic-ai-slim==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.4.6)\n",
      "\u001b[33mWARNING: huggingface-hub 1.1.4 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit>=3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.20.0->mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.20.0->mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.20.0->mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.27.1)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in /home/jovyan/.local/lib/python3.10/site-packages (from jsonschema-path>=0.3.4->fastmcp) (0.4.4)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /home/jovyan/.local/lib/python3.10/site-packages (from keyring>=25.6.0->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (3.4.1)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /home/jovyan/.local/lib/python3.10/site-packages (from keyring>=25.6.0->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (0.9.0)\n",
      "Requirement already satisfied: importlib_metadata>=4.11.4 in /home/jovyan/.local/lib/python3.10/site-packages (from keyring>=25.6.0->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (8.7.0)\n",
      "Requirement already satisfied: jaraco.classes in /home/jovyan/.local/lib/python3.10/site-packages (from keyring>=25.6.0->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (3.4.0)\n",
      "Requirement already satisfied: jaraco.functools in /home/jovyan/.local/lib/python3.10/site-packages (from keyring>=25.6.0->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (4.3.0)\n",
      "Requirement already satisfied: jaraco.context in /home/jovyan/.local/lib/python3.10/site-packages (from keyring>=25.6.0->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (6.0.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/jovyan/.local/lib/python3.10/site-packages (from importlib_metadata>=4.11.4->keyring>=25.6.0->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (3.23.0)\n",
      "Requirement already satisfied: executing>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (2.2.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<1.39.0,>=1.35.0 in /home/jovyan/.local/lib/python3.10/site-packages (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation>=0.41b0 in /home/jovyan/.local/lib/python3.10/site-packages (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.59b0)\n",
      "Requirement already satisfied: opentelemetry-sdk<1.39.0,>=1.35.0 in /home/jovyan/.local/lib/python3.10/site-packages (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.38.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<1.39.0,>=1.35.0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<1.39.0,>=1.35.0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.38.0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<1.39.0,>=1.35.0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-sdk<1.39.0,>=1.35.0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.59b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-httpx>=0.42b0 in /home/jovyan/.local/lib/python3.10/site-packages (from logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.59b0)\n",
      "Requirement already satisfied: invoke<3.0.0,>=2.2.0 in /home/jovyan/.local/lib/python3.10/site-packages (from mistralai>=1.9.10->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (2.2.1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation>=0.41b0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (1.17.3)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.59b0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation-httpx>=0.42b0->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.59b0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic[email]>=2.11.7->fastmcp) (2.3.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp) (2.8.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cryptography->authlib>=1.6.5->fastmcp) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=2.0.0->cryptography->authlib>=1.6.5->fastmcp) (2.23)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jovyan/.local/lib/python3.10/site-packages (from rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jovyan/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.18.0->pydantic-ai) (0.1.2)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.35->fastmcp) (8.3.0)\n",
      "Requirement already satisfied: more-itertools in /home/jovyan/.local/lib/python3.10/site-packages (from jaraco.classes->keyring>=25.6.0->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (10.8.0)\n",
      "Requirement already satisfied: backports.tarfile in /home/jovyan/.local/lib/python3.10/site-packages (from jaraco.context->keyring>=25.6.0->py-key-value-aio[disk,keyring,memory]<0.3.0,>=0.2.8->fastmcp) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install python-dotenv ipywidgets pydantic-ai fastmcp openai nest-asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import nest_asyncio\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from fastmcp import Client\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "# Enable nested asyncio for Jupyter notebooks\n",
    "nest_asyncio.apply()\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Set Up API Keys\n",
    "\n",
    "You need an OpenAI API key or a NRP API key to use this agent. Create a `.env` file with:\n",
    "```\n",
    "OPENAI_API_KEY=your_openai_key\n",
    "\n",
    "NRP_API_KEY=your_nrp_key\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenAI API key found\n",
      "✓ NRP API key found\n",
      "✓ Using OpenAI GPT-4o-mini\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check API keys\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "nrp_key = os.getenv('NRP_API_KEY')\n",
    "\n",
    "if not openai_key:\n",
    "    print(\"⚠️ Warning: OPENAI_API_KEY not set!\")\n",
    "else:\n",
    "    print(\"✓ OpenAI API key found\")\n",
    "\n",
    "if not nrp_key:\n",
    "    print(\"⚠️ Warning: NRP_API_KEY not set!\")\n",
    "else:\n",
    "    print(\"✓ NRP API key found\")\n",
    "\n",
    "# Choose your model: \"openai\" or \"nrp\"\n",
    "MODEL = \"openai\"  # Change this to \"nrp\" to use Qwen3\n",
    "\n",
    "if MODEL == \"openai\":\n",
    "    print(\"✓ Using OpenAI GPT-4o-mini\")\n",
    "elif MODEL == \"nrp\":\n",
    "    print(\"✓ Using NRP Qwen3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Initialize MCP Client\n",
    "\n",
    "The MCP (Model Context Protocol) client connects to the dataset search service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ MCP client initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MCP client for dataset search\n",
    "mcp_client = Client(\"https://wenokn.fastmcp.app/mcp\")\n",
    "print(\"✓ MCP client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create the Agent\n",
    "\n",
    "This is the core of our application. The agent:\n",
    "- Understands natural language questions\n",
    "- Uses the search_datasets tool to find relevant datasets\n",
    "- Maintains conversation history\n",
    "- Can answer follow-up questions about dataset metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Agent created successfully with openai!\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class AgentContext:\n",
    "    \"\"\"Stores information about the current dataset being discussed\"\"\"\n",
    "    current_dataset: Optional[dict] = None\n",
    "\n",
    "def get_model_config(model_name: str = \"openai\"):\n",
    "    \"\"\"Get model configuration based on model name.\"\"\"\n",
    "    if model_name == \"nrp\":\n",
    "        # Configure for NRP\n",
    "        os.environ['OPENAI_BASE_URL'] = 'https://ellm.nrp-nautilus.io/v1'\n",
    "        os.environ['OPENAI_API_KEY'] = os.getenv('NRP_API_KEY', '')\n",
    "        return 'openai:qwen3'\n",
    "    else:\n",
    "        # Configure for OpenAI\n",
    "        if 'OPENAI_BASE_URL' in os.environ:\n",
    "            del os.environ['OPENAI_BASE_URL']\n",
    "        return 'openai:gpt-4o-mini'\n",
    "\n",
    "# Create the agent with selected model\n",
    "agent = Agent(\n",
    "    model=get_model_config(MODEL),\n",
    "    deps_type=AgentContext,\n",
    "    system_prompt=\"\"\"You are a helpful assistant that helps users find and learn about California Landscape Metrics datasets.\n",
    "\n",
    "You have access to a search_datasets tool that can find relevant datasets based on user queries.\n",
    "\n",
    "When a user asks about a topic:\n",
    "1. Use the search_datasets tool to find the most relevant dataset\n",
    "2. Present the top result with key information (title, description, units)\n",
    "3. Answer any follow-up questions about the dataset metadata\n",
    "\n",
    "The conversation history is provided in this format:\n",
    "User: <question1>\n",
    "Assistant: <answer1>\n",
    "User: <question2>\n",
    "\n",
    "Use this history to understand context for follow-up questions.\n",
    "\n",
    "Be concise and helpful!\"\"\"\n",
    ")\n",
    "\n",
    "@agent.tool\n",
    "async def search_datasets(\n",
    "    ctx: RunContext[AgentContext],\n",
    "    query: str,\n",
    "    top_k: int = 3\n",
    ") -> dict:\n",
    "    \"\"\"Search for datasets related to the query.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query (e.g., 'carbon turnover', 'burn probability')\n",
    "        top_k: Number of results to return (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with search results and metadata\n",
    "    \"\"\"\n",
    "    async with mcp_client:\n",
    "        result = await mcp_client.call_tool(\n",
    "            \"search_datasets\",\n",
    "            {\"query\": query, \"top_k\": top_k}\n",
    "        )\n",
    "        \n",
    "        data = result.data\n",
    "        if data.get('success') and data.get('datasets'):\n",
    "            # Store the top dataset in context for follow-up questions\n",
    "            best_dataset = data['datasets'][0]\n",
    "            ctx.deps.current_dataset = best_dataset\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'top_dataset': best_dataset,\n",
    "                'alternatives': data['datasets'][1:] if len(data['datasets']) > 1 else [],\n",
    "                'message': f\"Found: {best_dataset['title']}\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'message': 'No datasets found',\n",
    "                'error': data.get('error', 'Unknown error')\n",
    "            }\n",
    "\n",
    "print(f\"✓ Agent created successfully with {MODEL}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Add Conversation History Management\n",
    "\n",
    "This wrapper class manages the conversation history, making the agent \"remember\" previous exchanges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Conversational agent ready with openai (timeout: 60s)!\n"
     ]
    }
   ],
   "source": [
    "class ConversationalAgent:\n",
    "    \"\"\"Wrapper that adds conversation history to the agent\"\"\"\n",
    "    \n",
    "    def __init__(self, agent, model_name=\"openai\"):\n",
    "        self.agent = agent\n",
    "        self.model_name = model_name\n",
    "        self.history = []  # Stores conversation history\n",
    "        # Set default timeout based on model\n",
    "        self.default_timeout = 180 if model_name == \"nrp\" else 60\n",
    "    \n",
    "    async def ask(self, question: str, timeout: int = None) -> str:\n",
    "        \"\"\"Ask a question and get a response.\n",
    "        \n",
    "        Args:\n",
    "            question: The user's question\n",
    "            timeout: Maximum seconds to wait for response (uses default if None)\n",
    "        \n",
    "        Returns:\n",
    "            The agent's response as a string\n",
    "        \"\"\"\n",
    "        # Use default timeout if not specified\n",
    "        if timeout is None:\n",
    "            timeout = self.default_timeout\n",
    "            \n",
    "        # Build the full input with history\n",
    "        if self.history:\n",
    "            full_input = \"\\n\".join(self.history) + f\"\\nUser: {question}\"\n",
    "        else:\n",
    "            full_input = f\"User: {question}\"\n",
    "        \n",
    "        try:\n",
    "            # Run the agent with timeout\n",
    "            result = await asyncio.wait_for(\n",
    "                self.agent.run(full_input, deps=AgentContext()),\n",
    "                timeout=timeout\n",
    "            )\n",
    "            \n",
    "            # Extract the response\n",
    "            response = result.output if hasattr(result, 'output') else str(result)\n",
    "            \n",
    "            # Update history\n",
    "            self.history.append(f\"User: {question}\")\n",
    "            self.history.append(f\"Assistant: {response}\")\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except asyncio.TimeoutError:\n",
    "            return f\"Error: Request timed out after {timeout} seconds. Try a simpler question or switch to OpenAI model.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error: {type(e).__name__}: {str(e)}\"\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear the conversation history\"\"\"\n",
    "        self.history = []\n",
    "\n",
    "# Create the conversational agent with model-aware timeout\n",
    "conv_agent = ConversationalAgent(agent, model_name=MODEL)\n",
    "print(f\"✓ Conversational agent ready with {MODEL} (timeout: {conv_agent.default_timeout}s)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create Chat Interface\n",
    "\n",
    "A simple, user-friendly chat interface using Jupyter widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Chat interface ready!\n"
     ]
    }
   ],
   "source": [
    "class SimpleChatInterface:\n",
    "    \"\"\"Simple chat interface for the agent\"\"\"\n",
    "    \n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "        self.messages = []\n",
    "        \n",
    "        # Create UI components\n",
    "        self.output_area = widgets.VBox(\n",
    "            layout=widgets.Layout(\n",
    "                border='1px solid #ddd',\n",
    "                height='400px',\n",
    "                overflow_y='auto',\n",
    "                padding='10px',\n",
    "                margin='10px 0'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.input_box = widgets.Textarea(\n",
    "            placeholder='Ask about datasets (e.g., \"Find datasets about carbon turnover\")...',\n",
    "            layout=widgets.Layout(width='100%', height='80px')\n",
    "        )\n",
    "        \n",
    "        self.send_button = widgets.Button(\n",
    "            description='Send',\n",
    "            button_style='primary',\n",
    "            layout=widgets.Layout(width='100px')\n",
    "        )\n",
    "        \n",
    "        self.clear_button = widgets.Button(\n",
    "            description='Clear',\n",
    "            button_style='warning',\n",
    "            layout=widgets.Layout(width='100px', margin='0 0 0 10px')\n",
    "        )\n",
    "        \n",
    "        self.status_label = widgets.HTML(value=\"✅ Ready\")\n",
    "        \n",
    "        # Connect buttons\n",
    "        self.send_button.on_click(self.on_send)\n",
    "        self.clear_button.on_click(self.on_clear)\n",
    "        \n",
    "        # Layout\n",
    "        button_row = widgets.HBox([self.send_button, self.clear_button, self.status_label])\n",
    "        self.interface = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>🤖 Dataset Search Agent</h3>\"),\n",
    "            self.output_area,\n",
    "            self.input_box,\n",
    "            button_row\n",
    "        ])\n",
    "        \n",
    "        # Welcome message\n",
    "        self.add_message(\n",
    "            \"Welcome! I can help you find California Landscape Metrics datasets.\\n\\n\"\n",
    "            \"Try asking:\\n\"\n",
    "            \"• Find datasets about carbon turnover\\n\"\n",
    "            \"• What datasets are available for burn probability?\\n\"\n",
    "            \"• Tell me about the units used in this dataset\\n\"\n",
    "            \"• What's the description of this dataset?\",\n",
    "            \"system\"\n",
    "        )\n",
    "    \n",
    "    def add_message(self, text, role=\"user\"):\n",
    "        \"\"\"Add a message to the chat display\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        if role == \"user\":\n",
    "            color = \"#007bff\"\n",
    "            icon = \"👤\"\n",
    "            label = \"You\"\n",
    "            bg = \"#e7f3ff\"\n",
    "        elif role == \"assistant\":\n",
    "            color = \"#28a745\"\n",
    "            icon = \"🤖\"\n",
    "            label = \"Agent\"\n",
    "            bg = \"#e8f5e9\"\n",
    "        else:\n",
    "            color = \"#6c757d\"\n",
    "            icon = \"ℹ️\"\n",
    "            label = \"System\"\n",
    "            bg = \"#f8f9fa\"\n",
    "        \n",
    "        message = widgets.HTML(\n",
    "            value=f\"\"\"\n",
    "            <div style='margin: 10px 0; padding: 10px; background: {bg}; \n",
    "                        border-radius: 8px; border-left: 4px solid {color};'>\n",
    "                <div style='display: flex; justify-content: space-between; margin-bottom: 5px;'>\n",
    "                    <strong style='color: {color};'>{icon} {label}</strong>\n",
    "                    <span style='color: #999; font-size: 0.85em;'>{timestamp}</span>\n",
    "                </div>\n",
    "                <div style='white-space: pre-wrap;'>{text}</div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        self.messages.append(message)\n",
    "        self.output_area.children = tuple(self.messages)\n",
    "    \n",
    "    def on_send(self, button):\n",
    "        \"\"\"Handle send button click\"\"\"\n",
    "        question = self.input_box.value.strip()\n",
    "        if not question:\n",
    "            return\n",
    "        \n",
    "        # Show user message\n",
    "        self.add_message(question, \"user\")\n",
    "        self.input_box.value = \"\"\n",
    "        \n",
    "        # Disable input while processing\n",
    "        self.send_button.disabled = True\n",
    "        self.input_box.disabled = True\n",
    "        self.status_label.value = \"<span style='color: orange;'>⏳ Thinking...</span>\"\n",
    "        \n",
    "        try:\n",
    "            # Get response from agent\n",
    "            response = asyncio.get_event_loop().run_until_complete(\n",
    "                self.agent.ask(question)\n",
    "            )\n",
    "            \n",
    "            # Show agent response\n",
    "            self.add_message(response, \"assistant\")\n",
    "            self.status_label.value = \"<span style='color: green;'>✅ Ready</span>\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error: {str(e)}\"\n",
    "            self.add_message(error_msg, \"system\")\n",
    "            self.status_label.value = \"<span style='color: red;'>❌ Error</span>\"\n",
    "        \n",
    "        finally:\n",
    "            # Re-enable input\n",
    "            self.send_button.disabled = False\n",
    "            self.input_box.disabled = False\n",
    "    \n",
    "    def on_clear(self, button):\n",
    "        \"\"\"Clear the chat\"\"\"\n",
    "        self.messages = []\n",
    "        self.agent.clear_history()\n",
    "        self.output_area.children = tuple(self.messages)\n",
    "        self.add_message(\n",
    "            \"Chat cleared! Ready for new questions.\",\n",
    "            \"system\"\n",
    "        )\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the chat interface\"\"\"\n",
    "        clear_output(wait=True)\n",
    "        display(self.interface)\n",
    "\n",
    "print(\"✓ Chat interface ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Launch the Chat Interface\n",
    "\n",
    "Run this cell to start chatting with your agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7181b9c105c4a4491d78cf9314dc987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>🤖 Dataset Search Agent</h3>'), VBox(children=(HTML(value=\"\\n            <div st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and display the chat interface\n",
    "chat = SimpleChatInterface(conv_agent)\n",
    "chat.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Questions to Try\n",
    "\n",
    "1. **Find datasets about carbon turnover**\n",
    "2. **What datasets are available for burn probability?**\n",
    "3. **What are the units for this dataset?**\n",
    "4. **Can you describe this dataset in more detail?**\n",
    "5. **Search for datasets related to fire risk**\n",
    "\n",
    "## How This Works\n",
    "\n",
    "### Agent Architecture\n",
    "\n",
    "```\n",
    "User Question\n",
    "     ↓\n",
    "ConversationalAgent (adds history)\n",
    "     ↓\n",
    "Pydantic AI Agent (processes with context)\n",
    "     ↓\n",
    "search_datasets tool (queries MCP server)\n",
    "     ↓\n",
    "Response (with dataset metadata)\n",
    "```\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **LLM (Large Language Model)**: The AI brain that processes natural language and generates responses\n",
    "   - OpenAI GPT-4o-mini: Fast and cost-effective model from OpenAI\n",
    "   - NRP Qwen3: Open-source model hosted on NRP infrastructure\n",
    "2. **Agent**: The core orchestrator that understands questions and decides when to use tools\n",
    "3. **Tool (search_datasets)**: Connects to the MCP server to search for datasets\n",
    "4. **Context**: Stores the current dataset being discussed for follow-up questions\n",
    "5. **History**: Maintains conversation flow to enable contextual responses\n",
    "6. **Chat Interface**: User-friendly UI for interaction\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "To extend this agent, you could:\n",
    "- Add more tools (statistics, visualization, etc.)\n",
    "- Improve the system prompt for better responses\n",
    "- Add filtering options for search results\n",
    "- Add support for multiple datasets simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
