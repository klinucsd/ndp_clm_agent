{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213794c8-4f58-4b04-a005-5f7e7b644481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "!pip install python-dotenv ipywidgets pydantic-ai fastmcp openai nest-asyncio folium matplotlib markdown aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4abe54-8282-415f-a994-f98fe1092f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from fastmcp import Client\n",
    "import asyncio\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Base configuration for CLM GeoServer\n",
    "BASE_CONFIG = {\n",
    "    \"wcs_base_url\": \"https://sparcal.sdsc.edu/geoserver\",\n",
    "    \"wfs_base_url\": \"https://sparcal.sdsc.edu/geoserver/boundary/wfs\",\n",
    "    \"feature_id\": \"boundary:ca_counties\",\n",
    "    \"filter_column\": \"name\"\n",
    "}\n",
    "\n",
    "# Initialize CLM MCP client\n",
    "mcp_client = Client(\"https://wenokn.fastmcp.app/mcp\")\n",
    "print(\"✓ CLM MCP client configured\")\n",
    "\n",
    "# Check API keys\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "nrp_key = os.getenv('NRP_API_KEY')\n",
    "dc_key = os.getenv('DC_API_KEY')\n",
    "\n",
    "if not openai_key:\n",
    "    print(\"⚠️ Warning: OPENAI_API_KEY not set!\")\n",
    "else:\n",
    "    print(\"✓ OpenAI API key found\")\n",
    "\n",
    "if not nrp_key:\n",
    "    print(\"⚠️ Warning: NRP_API_KEY not set!\")\n",
    "else:\n",
    "    print(\"✓ NRP API key found\")\n",
    "    \n",
    "if not dc_key:\n",
    "    print(\"⚠️ Warning: DC_API_KEY not set! Get one from https://datacommons.org/\")\n",
    "else:\n",
    "    print(\"✓ Data Commons API key found\")\n",
    "\n",
    "# Choose your model\n",
    "MODEL = \"openai\"  # \"openai\" or \"nrp\"\n",
    "\n",
    "if MODEL == \"openai\":\n",
    "    print(\"✓ Using OpenAI GPT-4o-mini\")\n",
    "elif MODEL == \"nrp\":\n",
    "    print(\"✓ Using NRP Qwen3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169ab9b-7c5f-4b16-bb1e-08c3d16ee559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, List\n",
    "import asyncio\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from fastmcp import Client\n",
    "import os\n",
    "\n",
    "@dataclass\n",
    "class AgentContext:\n",
    "    \"\"\"Context to store discovered dataset information.\"\"\"\n",
    "    current_coverage_id: Optional[str] = None\n",
    "    current_dataset_info: Optional[dict] = None\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"wcs_base_url\": \"https://sparcal.sdsc.edu/geoserver\",\n",
    "    \"wfs_base_url\": \"https://sparcal.sdsc.edu/geoserver/boundary/wfs\",\n",
    "    \"feature_id\": \"boundary:ca_counties\",\n",
    "    \"filter_column\": \"name\"\n",
    "}\n",
    "\n",
    "def get_model_config(model_name: str = \"openai\"):\n",
    "    \"\"\"\n",
    "    Get model configuration based on model name.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Either \"openai\" or \"nrp\"\n",
    "    \n",
    "    Returns:\n",
    "        Model configuration for pydantic-ai\n",
    "    \"\"\"\n",
    "    if model_name == \"nrp\":\n",
    "        # For NRP, we need to set environment variables before creating the model\n",
    "        # Store original values to restore later if needed\n",
    "        original_base_url = os.environ.get('OPENAI_BASE_URL')\n",
    "        original_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "        \n",
    "        # Set NRP-specific configuration\n",
    "        os.environ['OPENAI_BASE_URL'] = 'https://ellm.nrp-nautilus.io/v1'\n",
    "        os.environ['OPENAI_API_KEY'] = os.getenv('NRP_API_KEY', '')\n",
    "        \n",
    "        # Use the string format which pydantic-ai will parse\n",
    "        return 'openai:qwen3'\n",
    "    else:\n",
    "        # Restore default OpenAI settings\n",
    "        if 'OPENAI_BASE_URL' in os.environ:\n",
    "            del os.environ['OPENAI_BASE_URL']\n",
    "        # Restore original OpenAI key\n",
    "        if os.getenv('OPENAI_API_KEY_ORIGINAL'):\n",
    "            os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY_ORIGINAL')\n",
    "        \n",
    "        return 'openai:gpt-4o-mini'\n",
    "\n",
    "def create_internal_agent(model_name: str = \"openai\"):\n",
    "    \"\"\"\n",
    "    Create and configure the Pydantic AI agent.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Either \"openai\" for GPT-4o-mini or \"nrp\" for Qwen3\n",
    "    \"\"\"\n",
    "    \n",
    "    model_config = get_model_config(model_name)\n",
    "    \n",
    "    agent = Agent(\n",
    "        model=model_config,\n",
    "        deps_type=AgentContext,\n",
    "        retries=2,\n",
    "        system_prompt=\"\"\"You are an expert in analyzing California Landscape Metrics datasets.\n",
    "\n",
    "The input you receive will be the full conversation history in the format:\n",
    "User: <question1>\n",
    "Assistant: <answer1>\n",
    "User: <question2>\n",
    "Assistant: <answer2>\n",
    "...\n",
    "User: <current question>\n",
    "\n",
    "Use this history to understand the context for follow-up questions.\n",
    "\n",
    "You have access to these tools:\n",
    "1. search_and_select_dataset: Search for the most relevant dataset based on the question\n",
    "2. get_county_statistics: Compute statistics for one or more counties\n",
    "3. get_area_above_threshold: Calculate percentage/area above a threshold for one or more counties\n",
    "4. get_area_below_threshold: Calculate percentage/area below a threshold for one or more counties\n",
    "5. show_map: Display a map visualization of the current dataset\n",
    "6. get_value_distribution: Get value distribution for one or more counties (for charts/histograms)\n",
    "\n",
    "**CRITICAL RULE FOR SEARCH:**\n",
    "When calling search_and_select_dataset, construct a search query that represents the current user's question.\n",
    "If the current question is a follow-up (e.g., \"How about San Diego?\"), incorporate context from the history to make it a standalone query (e.g., \"What is the average carbon turnover time in San Diego?\").\n",
    "DO NOT pass vague follow-up phrases directly; always create a meaningful, context-aware query.\n",
    "DO NOT use the entire history as the query.\n",
    "When calling search_and_select_dataset, please remove the terms related to statistics like \"average\" and \"mean\" and the place names from the question like 'San Diego' or 'Los Angeles'. \n",
    "For example, for the question \"What is the average carbon turnover time in Los Angeles?\", use \"carbon turnover time\" to call search_and_select_dataset.\n",
    "\n",
    "**WORKFLOW:**\n",
    "1. If needed, start by calling search_and_select_dataset with the constructed query.\n",
    "   - If a similar dataset was used in previous interactions (based on history), you may skip searching if it's clearly the same topic.\n",
    "2. Once the dataset is selected, use the other tools to answer the question.\n",
    "3. Include the dataset name and units in your final answer for context.\n",
    "\n",
    "**For statistical questions:**\n",
    "- Use get_county_statistics for mean, median, min, max, std\n",
    "- Pass counties=None to get all counties\n",
    "- For rankings, get all counties and sort results\n",
    "\n",
    "**For threshold questions:**\n",
    "- Use get_area_above_threshold or get_area_below_threshold\n",
    "- Pass counties=None to get all counties\n",
    "- For questions about many/all counties, you can use counties=None, but if concerned about timeouts, first get list of counties from get_county_statistics and sample 10-20\n",
    "\n",
    "**For map visualization requests:**\n",
    "- When users ask to \"show the map\", \"visualize\", \"display map\", or similar requests, use the show_map tool\n",
    "- You must have a dataset selected first (via search_and_select_dataset)\n",
    "- The tool will return a special marker that the interface will use to render the map\n",
    "\n",
    "**For distribution/histogram requests:**\n",
    "- When users ask to \"show distribution\", \"show histogram\", \"compare distributions\", \"data distribution\", or similar requests, use the get_value_distribution tool\n",
    "- You must have a dataset selected first (via search_and_select_dataset)\n",
    "- CRITICAL: For comparing distributions between regions, pass ALL county names as a LIST in a SINGLE call to get_value_distribution\n",
    "  Example: get_value_distribution(counties=[\"San Diego\", \"Los Angeles\"]) - NOT separate calls\n",
    "- For single region, pass one county name as a string or single-item list\n",
    "- For overview of all regions, pass counties=None (but this may be slow for many counties)\n",
    "- The tool will return distribution data that the interface will visualize as charts\n",
    "- DO NOT call get_value_distribution multiple times - always use ONE call with a list of counties\n",
    "\n",
    "**Answer format:**\n",
    "- Be precise with numbers and include units from the dataset\n",
    "- Provide clear, concise answers\n",
    "- Mention the dataset being used\n",
    "- For distribution requests, briefly describe what the chart shows\n",
    "\n",
    "\"\"\",\n",
    "    )\n",
    "\n",
    "    @agent.tool\n",
    "    async def search_and_select_dataset(\n",
    "        ctx: RunContext[AgentContext],\n",
    "        question: str,\n",
    "        top_k: int = 3\n",
    "    ) -> dict:\n",
    "        \"\"\"Search for and select the most relevant dataset.\"\"\"\n",
    "        async with mcp_client:\n",
    "            result = await mcp_client.call_tool(\n",
    "                \"search_datasets\",\n",
    "                {\"query\": question, \"top_k\": top_k}\n",
    "            )\n",
    "            \n",
    "            data = result.data\n",
    "            if data.get('success') and data.get('datasets'):\n",
    "                best_dataset = data['datasets'][0]\n",
    "                ctx.deps.current_coverage_id = best_dataset['wcs_coverage_id']\n",
    "                ctx.deps.current_dataset_info = best_dataset\n",
    "                \n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'selected_dataset': best_dataset,\n",
    "                    'alternatives': data['datasets'][1:] if len(data['datasets']) > 1 else [],\n",
    "                    'message': f\"Selected: {best_dataset['title']}\"\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'success': False,\n",
    "                    'message': 'No suitable datasets found',\n",
    "                    'error': data.get('error', 'Unknown error')\n",
    "                }\n",
    "\n",
    "    @agent.tool\n",
    "    async def get_county_statistics(\n",
    "        ctx: RunContext[AgentContext],\n",
    "        counties: Optional[List[str]] = None,\n",
    "        stats: List[str] = None\n",
    "    ) -> dict:\n",
    "        \"\"\"Get statistics for one or more counties.\"\"\"\n",
    "        if not ctx.deps.current_coverage_id:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': 'No dataset selected. Call search_and_select_dataset first.'\n",
    "            }\n",
    "        \n",
    "        if stats is None:\n",
    "            stats = [\"mean\", \"median\", \"min\", \"max\", \"std\"]\n",
    "        \n",
    "        async with mcp_client:\n",
    "            result = await mcp_client.call_tool(\n",
    "                \"compute_zonal_stats\",\n",
    "                {\n",
    "                    **BASE_CONFIG,\n",
    "                    \"wcs_coverage_id\": ctx.deps.current_coverage_id,\n",
    "                    \"filter_value\": counties,\n",
    "                    \"stats\": stats,\n",
    "                    \"max_workers\": 16\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            response = result.data\n",
    "            if response.get('success'):\n",
    "                response['dataset_info'] = {\n",
    "                    'title': ctx.deps.current_dataset_info.get('title'),\n",
    "                    'units': ctx.deps.current_dataset_info.get('data_units')\n",
    "                }\n",
    "            return response\n",
    "\n",
    "    @agent.tool\n",
    "    async def get_area_above_threshold(\n",
    "        ctx: RunContext[AgentContext],\n",
    "        counties: Optional[List[str]] = None,\n",
    "        threshold: float = 100.0\n",
    "    ) -> dict:\n",
    "        \"\"\"Calculate the percentage and area above a threshold for one or more counties.\"\"\"\n",
    "        if not ctx.deps.current_coverage_id:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': 'No dataset selected. Call search_and_select_dataset first.'\n",
    "            }\n",
    "        \n",
    "        async with mcp_client:\n",
    "            result = await mcp_client.call_tool(\n",
    "                \"zonal_count\",\n",
    "                {\n",
    "                    **BASE_CONFIG,\n",
    "                    \"wcs_coverage_id\": ctx.deps.current_coverage_id,\n",
    "                    \"filter_value\": counties,\n",
    "                    \"threshold\": threshold,\n",
    "                    \"max_workers\": 16\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            zonal_data = result.data\n",
    "            if not zonal_data.get('success'):\n",
    "                return zonal_data\n",
    "            \n",
    "            processed = []\n",
    "            for stats in zonal_data['data']:\n",
    "                county_name = stats[BASE_CONFIG['filter_column']]\n",
    "                valid = stats['valid_pixels']\n",
    "                above = stats['above_threshold_pixels']\n",
    "                pixel_area = stats['pixel_area_square_meters']\n",
    "                \n",
    "                percentage = (above / valid * 100) if valid > 0 else 0\n",
    "                area_sq_m = above * pixel_area\n",
    "                area_sq_km = area_sq_m / 1_000_000\n",
    "                \n",
    "                processed.append({\n",
    "                    'county': county_name,\n",
    "                    'threshold': threshold,\n",
    "                    'valid_pixels': valid,\n",
    "                    'above_threshold_pixels': above,\n",
    "                    'percentage': percentage,\n",
    "                    'area_square_meters': area_sq_m,\n",
    "                    'area_square_km': area_sq_km\n",
    "                })\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'data': processed,\n",
    "                'total_features': zonal_data['total_features'],\n",
    "                'processed_features': zonal_data['processed_features'],\n",
    "                'dataset_info': {\n",
    "                    'title': ctx.deps.current_dataset_info.get('title'),\n",
    "                    'units': ctx.deps.current_dataset_info.get('data_units')\n",
    "                }\n",
    "            }\n",
    "\n",
    "    @agent.tool\n",
    "    async def get_area_below_threshold(\n",
    "        ctx: RunContext[AgentContext],\n",
    "        counties: Optional[List[str]] = None,\n",
    "        threshold: float = 100.0\n",
    "    ) -> dict:\n",
    "        \"\"\"Calculate the percentage and area below a threshold for one or more counties.\"\"\"\n",
    "        if not ctx.deps.current_coverage_id:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': 'No dataset selected. Call search_and_select_dataset first.'\n",
    "            }\n",
    "        \n",
    "        async with mcp_client:\n",
    "            result = await mcp_client.call_tool(\n",
    "                \"zonal_count\",\n",
    "                {\n",
    "                    **BASE_CONFIG,\n",
    "                    \"wcs_coverage_id\": ctx.deps.current_coverage_id,\n",
    "                    \"filter_value\": counties,\n",
    "                    \"threshold\": threshold,\n",
    "                    \"max_workers\": 16\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            zonal_data = result.data\n",
    "            if not zonal_data.get('success'):\n",
    "                return zonal_data\n",
    "            \n",
    "            processed = []\n",
    "            for stats in zonal_data['data']:\n",
    "                county_name = stats[BASE_CONFIG['filter_column']]\n",
    "                valid = stats['valid_pixels']\n",
    "                above = stats['above_threshold_pixels']\n",
    "                below = valid - above\n",
    "                pixel_area = stats['pixel_area_square_meters']\n",
    "                \n",
    "                percentage = (below / valid * 100) if valid > 0 else 0\n",
    "                area_sq_m = below * pixel_area\n",
    "                area_sq_km = area_sq_m / 1_000_000\n",
    "                \n",
    "                processed.append({\n",
    "                    'county': county_name,\n",
    "                    'threshold': threshold,\n",
    "                    'valid_pixels': valid,\n",
    "                    'below_threshold_pixels': below,\n",
    "                    'percentage': percentage,\n",
    "                    'area_square_meters': area_sq_m,\n",
    "                    'area_square_km': area_sq_km\n",
    "                })\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'data': processed,\n",
    "                'total_features': zonal_data['total_features'],\n",
    "                'processed_features': zonal_data['processed_features'],\n",
    "                'dataset_info': {\n",
    "                    'title': ctx.deps.current_dataset_info.get('title'),\n",
    "                    'units': ctx.deps.current_dataset_info.get('data_units')\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    @agent.tool\n",
    "    async def show_map(ctx: RunContext[AgentContext]) -> dict:\n",
    "        \"\"\"Display a map visualization of the current dataset using WMS layer.\"\"\"\n",
    "        if not ctx.deps.current_dataset_info:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': 'No dataset selected. Call search_and_select_dataset first.'\n",
    "            }\n",
    "        \n",
    "        dataset = ctx.deps.current_dataset_info\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'action': 'show_map',\n",
    "            'map_data': {\n",
    "                'wms_base_url': dataset.get('wms_base_url'),\n",
    "                'wms_layer_name': dataset.get('wms_layer_name'),\n",
    "                'title': dataset.get('title'),\n",
    "                'description': dataset.get('description', ''),\n",
    "                'units': dataset.get('data_units', '')\n",
    "            },\n",
    "            'message': f\"Displaying map for: {dataset.get('title')}\"\n",
    "        }\n",
    "    \n",
    "    @agent.tool\n",
    "    async def get_value_distribution(\n",
    "        ctx: RunContext[AgentContext],\n",
    "        counties: Optional[List[str]] = None,\n",
    "        num_bins: int = 10\n",
    "    ) -> dict:\n",
    "        \"\"\"Get value distribution for one or more counties to create histograms/charts.\"\"\"\n",
    "        if not ctx.deps.current_coverage_id:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': 'No dataset selected. Call search_and_select_dataset first.'\n",
    "            }\n",
    "        \n",
    "        async with mcp_client:\n",
    "            result = await mcp_client.call_tool(\n",
    "                \"zonal_distribution\",\n",
    "                {\n",
    "                    **BASE_CONFIG,\n",
    "                    \"wcs_coverage_id\": ctx.deps.current_coverage_id,\n",
    "                    \"filter_value\": counties,\n",
    "                    \"num_bins\": num_bins,\n",
    "                    \"global_bins\": True,\n",
    "                    \"categorical_threshold\": 20,\n",
    "                    \"max_workers\": 16\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            dist_data = result.data\n",
    "            if dist_data.get('success'):\n",
    "                dist_data['dataset_info'] = {\n",
    "                    'title': ctx.deps.current_dataset_info.get('title'),\n",
    "                    'units': ctx.deps.current_dataset_info.get('data_units')\n",
    "                }\n",
    "                dist_data['action'] = 'show_distribution'\n",
    "            \n",
    "            return dist_data\n",
    "    \n",
    "    return agent\n",
    "\n",
    "class HistoryAwareAgent:\n",
    "    def __init__(self, model_name: str = \"openai\"):\n",
    "        \"\"\"\n",
    "        Initialize the agent with a specific model.\n",
    "        \n",
    "        Args:\n",
    "            model_name: Either \"openai\" or \"nrp\"\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.internal_agent = create_internal_agent(model_name)\n",
    "        self.history = []\n",
    "\n",
    "    async def run(self, question: str, timeout: int = 300, deps: Optional[AgentContext] = None) -> dict:\n",
    "        \"\"\"Run the agent with history-aware input.\"\"\"\n",
    "        full_input = \"\\n\".join(self.history) + (f\"\\nUser: {question}\" if self.history else f\"User: {question}\")\n",
    "\n",
    "        try:\n",
    "            result = await asyncio.wait_for(\n",
    "                self.internal_agent.run(full_input, deps=deps),\n",
    "                timeout=timeout\n",
    "            )\n",
    "            output = result.output if hasattr(result, 'output') else str(result)\n",
    "            \n",
    "            map_data = None\n",
    "            distribution_data = None\n",
    "            \n",
    "            if hasattr(result, 'all_messages'):\n",
    "                for msg in result.all_messages():\n",
    "                    if hasattr(msg, 'parts'):\n",
    "                        for part in msg.parts:\n",
    "                            if hasattr(part, 'content') and isinstance(part.content, dict):\n",
    "                                if part.content.get('action') == 'show_map':\n",
    "                                    map_data = part.content.get('map_data')\n",
    "                                elif part.content.get('action') == 'show_distribution':\n",
    "                                    new_dist = part.content\n",
    "                                    if distribution_data is None or len(new_dist.get('data', [])) > len(distribution_data.get('data', [])):\n",
    "                                        distribution_data = new_dist\n",
    "\n",
    "            self.history.append(f\"User: {question}\")\n",
    "            self.history.append(f\"Assistant: {output}\")\n",
    "\n",
    "            return {\n",
    "                'output': output,\n",
    "                'map_data': map_data,\n",
    "                'distribution_data': distribution_data\n",
    "            }\n",
    "        except asyncio.TimeoutError:\n",
    "            return {\n",
    "                'output': f\"Error: Question timed out after {timeout} seconds.\",\n",
    "                'map_data': None,\n",
    "                'distribution_data': None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'output': f\"Error: {type(e).__name__}: {str(e)[:200]}\",\n",
    "                'map_data': None,\n",
    "                'distribution_data': None\n",
    "            }\n",
    "\n",
    "# Create agents for both models\n",
    "def create_agent(model_name: str = \"openai\"):\n",
    "    \"\"\"\n",
    "    Factory function to create an agent with specified model.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Either \"openai\" or \"nrp\"\n",
    "    \n",
    "    Returns:\n",
    "        HistoryAwareAgent instance\n",
    "    \"\"\"\n",
    "    return HistoryAwareAgent(model_name=model_name)\n",
    "\n",
    "# Default agent (OpenAI)\n",
    "clm_agent = create_agent(MODEL)\n",
    "print(f\"✓ Agent created successfully with {MODEL}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc111b-643e-4c68-84e7-17e72ebe5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import json\n",
    "\n",
    "# MCP Configuration for Data Commons\n",
    "MCP_URL = \"http://localhost:3000/mcp\"\n",
    "MCP_HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Accept\": \"application/json, text/event-stream\"  # Important for SSE support!\n",
    "}\n",
    "\n",
    "async def parse_sse_response(response) -> list:\n",
    "    \"\"\"Parse Server-Sent Events (SSE) response.\"\"\"\n",
    "    messages = []\n",
    "    buffer = \"\"\n",
    "    \n",
    "    async for line in response.content:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\"data: \"):\n",
    "            buffer += line[6:] + \"\\n\"\n",
    "        elif line == \"data: [DONE]\":\n",
    "            if buffer.strip():\n",
    "                try:\n",
    "                    messages.append(json.loads(buffer.strip()))\n",
    "                except json.JSONDecodeError:\n",
    "                    pass\n",
    "            break\n",
    "    \n",
    "    # Handle last message if no [DONE] marker\n",
    "    if buffer.strip():\n",
    "        try:\n",
    "            messages.append(json.loads(buffer.strip()))\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    \n",
    "    return messages\n",
    "\n",
    "async def check_dc_mcp_server():\n",
    "    \"\"\"Check if Data Commons MCP server is running and responding correctly.\"\"\"\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            # Try to initialize connection\n",
    "            init_request = {\n",
    "                \"jsonrpc\": \"2.0\",\n",
    "                \"id\": 1,\n",
    "                \"method\": \"initialize\",\n",
    "                \"params\": {\n",
    "                    \"protocolVersion\": \"2024-11-05\",\n",
    "                    \"capabilities\": {},\n",
    "                    \"clientInfo\": {\n",
    "                        \"name\": \"notebook-client\",\n",
    "                        \"version\": \"1.0.0\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            async with session.post(\n",
    "                MCP_URL,\n",
    "                json=init_request,\n",
    "                headers=MCP_HEADERS\n",
    "            ) as resp:\n",
    "                if resp.status == 200:\n",
    "                    # Parse SSE response\n",
    "                    messages = await parse_sse_response(resp)\n",
    "                    \n",
    "                    if messages and 'result' in messages[0]:\n",
    "                        result = messages[0]['result']\n",
    "                        server_name = result.get('serverInfo', {}).get('name', 'Unknown')\n",
    "                        protocol = result.get('protocolVersion', 'Unknown')\n",
    "                        \n",
    "                        print(\"✓ Data Commons MCP server is running!\")\n",
    "                        print(f\"  Server: {server_name}\")\n",
    "                        print(f\"  Protocol: {protocol}\")\n",
    "                        print(f\"  Endpoint: {MCP_URL}\")\n",
    "                        return True\n",
    "                    else:\n",
    "                        print(\"⚠️ Server responded but no valid initialization data\")\n",
    "                        return False\n",
    "                else:\n",
    "                    print(f\"⚠️ DC MCP server returned status {resp.status}\")\n",
    "                    print(f\"   Make sure to use correct headers (SSE support)\")\n",
    "                    return False\n",
    "                    \n",
    "    except aiohttp.ClientConnectorError:\n",
    "        print(\"❌ Cannot connect to Data Commons MCP server!\")\n",
    "        print(\"   Start it with: uv tool run datacommons-mcp serve http --port 3000\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error checking DC MCP server: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# Quick test to list available tools\n",
    "async def list_dc_tools():\n",
    "    \"\"\"List available Data Commons tools.\"\"\"\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            # First initialize\n",
    "            init_request = {\n",
    "                \"jsonrpc\": \"2.0\",\n",
    "                \"id\": 1,\n",
    "                \"method\": \"initialize\",\n",
    "                \"params\": {\n",
    "                    \"protocolVersion\": \"2024-11-05\",\n",
    "                    \"capabilities\": {},\n",
    "                    \"clientInfo\": {\"name\": \"notebook-client\", \"version\": \"1.0.0\"}\n",
    "                }\n",
    "            }\n",
    "            async with session.post(MCP_URL, json=init_request, headers=MCP_HEADERS) as resp:\n",
    "                if resp.status != 200:\n",
    "                    return\n",
    "                await parse_sse_response(resp)  # Drain the response\n",
    "            \n",
    "            # Then list tools\n",
    "            tools_request = {\n",
    "                \"jsonrpc\": \"2.0\",\n",
    "                \"id\": 2,\n",
    "                \"method\": \"tools/list\",\n",
    "                \"params\": {}\n",
    "            }\n",
    "            \n",
    "            async with session.post(MCP_URL, json=tools_request, headers=MCP_HEADERS) as resp:\n",
    "                if resp.status == 200:\n",
    "                    messages = await parse_sse_response(resp)\n",
    "                    if messages and 'result' in messages[0]:\n",
    "                        tools = messages[0]['result'].get('tools', [])\n",
    "                        print(f\"\\n✓ Found {len(tools)} available tools:\")\n",
    "                        for tool in tools:\n",
    "                            print(f\"  - {tool['name']}: {tool.get('description', 'No description')[:60]}...\")\n",
    "                        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Could not list tools: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run checks\n",
    "print(\"Checking Data Commons MCP Server...\")\n",
    "server_ok = await check_dc_mcp_server()\n",
    "\n",
    "if server_ok:\n",
    "    await list_dc_tools()\n",
    "else:\n",
    "    print(\"\\n⚠️ Please ensure the server is running before proceeding.\")\n",
    "    print(\"   In a terminal, run:\")\n",
    "    print(\"   uv tool run datacommons-mcp serve http --port 3000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba173c8-ef24-4c40-a0f9-32300a84f87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "import json\n",
    "\n",
    "# MCP Configuration\n",
    "MCP_PORT = 3000\n",
    "MCP_URL = f\"http://localhost:{MCP_PORT}/mcp\"\n",
    "MCP_HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Accept\": \"application/json, text/event-stream\",\n",
    "}\n",
    "\n",
    "class AgentDeps(BaseModel):\n",
    "    \"\"\"Dependencies for Data Commons agent.\"\"\"\n",
    "    llm_api_key: str = Field(description=\"API key for the LLM endpoint\")\n",
    "    dc_api_key: str = Field(description=\"Data Commons API key\")\n",
    "\n",
    "class DataCommonsMCPClient:\n",
    "    \"\"\"Client for Data Commons MCP server.\"\"\"\n",
    "    \n",
    "    def __init__(self, url: str = MCP_URL):\n",
    "        self.url = url\n",
    "        self.session: Optional[aiohttp.ClientSession] = None\n",
    "\n",
    "    async def __aenter__(self):\n",
    "        self.session = aiohttp.ClientSession()\n",
    "        return self\n",
    "\n",
    "    async def __aexit__(self, *exc):\n",
    "        if self.session:\n",
    "            await self.session.close()\n",
    "\n",
    "    async def _parse_sse_response(self, resp: aiohttp.ClientResponse) -> List[Dict]:\n",
    "        \"\"\"Parse server-sent events response.\"\"\"\n",
    "        messages: List[Dict] = []\n",
    "        buffer = \"\"\n",
    "\n",
    "        async for line in resp.content:\n",
    "            line = line.decode(\"utf-8\").strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if line.startswith(\"data: \"):\n",
    "                buffer += line[6:] + \"\\n\"\n",
    "            elif line == \"data: [DONE]\":\n",
    "                if buffer.strip():\n",
    "                    try:\n",
    "                        messages.append(json.loads(buffer.strip()))\n",
    "                    except json.JSONDecodeError:\n",
    "                        pass\n",
    "                buffer = \"\"\n",
    "                break\n",
    "\n",
    "        # Handle last message if no [DONE] marker\n",
    "        if buffer.strip():\n",
    "            try:\n",
    "                messages.append(json.loads(buffer.strip()))\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "\n",
    "        return messages\n",
    "\n",
    "    async def _rpc(self, payload: Dict) -> List[Dict]:\n",
    "        \"\"\"Make RPC call to MCP server.\"\"\"\n",
    "        async with self.session.post(self.url, json=payload, headers=MCP_HEADERS) as resp:\n",
    "            if resp.status != 200:\n",
    "                txt = await resp.text()\n",
    "                raise RuntimeError(f\"MCP HTTP {resp.status}: {txt}\")\n",
    "            return await self._parse_sse_response(resp)\n",
    "\n",
    "    async def initialize(self) -> Dict:\n",
    "        \"\"\"Initialize MCP connection.\"\"\"\n",
    "        payload = {\n",
    "            \"jsonrpc\": \"2.0\",\n",
    "            \"id\": 1,\n",
    "            \"method\": \"initialize\",\n",
    "            \"params\": {\n",
    "                \"protocolVersion\": \"2024-11-05\",\n",
    "                \"capabilities\": {},\n",
    "                \"clientInfo\": {\"name\": \"pydantic-ai-agent\", \"version\": \"1.0\"},\n",
    "            },\n",
    "        }\n",
    "        msgs = await self._rpc(payload)\n",
    "        return msgs[0] if msgs else {}\n",
    "\n",
    "    async def call_tool(self, name: str, arguments: Dict) -> str:\n",
    "        \"\"\"Call a tool on the MCP server.\"\"\"\n",
    "        payload = {\n",
    "            \"jsonrpc\": \"2.0\",\n",
    "            \"id\": 3,\n",
    "            \"method\": \"tools/call\",\n",
    "            \"params\": {\"name\": name, \"arguments\": arguments},\n",
    "        }\n",
    "        msgs = await self._rpc(payload)\n",
    "        if not msgs:\n",
    "            raise RuntimeError(\"Empty MCP response\")\n",
    "        result = msgs[0].get(\"result\", {})\n",
    "        text_parts = [\n",
    "            block.get(\"text\", \"\")\n",
    "            for block in result.get(\"content\", [])\n",
    "            if block.get(\"type\") == \"text\"\n",
    "        ]\n",
    "        return \"\\n\".join(text_parts) or json.dumps(result, indent=2)\n",
    "\n",
    "# Tool wrapper functions\n",
    "async def search_indicators(\n",
    "    ctx: RunContext[AgentDeps],\n",
    "    query: str,\n",
    "    places: Optional[List[str]] = None,\n",
    "    parent_place: Optional[str] = None,\n",
    "    include_topics: bool = True,\n",
    "    maybe_bilateral: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Search for indicators in Data Commons.\"\"\"\n",
    "    async with DataCommonsMCPClient() as client:\n",
    "        await client.initialize()\n",
    "        args: Dict[str, Any] = {\n",
    "            \"query\": query,\n",
    "            \"include_topics\": include_topics,\n",
    "            \"maybe_bilateral\": maybe_bilateral,\n",
    "        }\n",
    "        if places:\n",
    "            args[\"places\"] = places\n",
    "        if parent_place:\n",
    "            args[\"parent_place\"] = parent_place\n",
    "        return await client.call_tool(\"search_indicators\", args)\n",
    "\n",
    "async def get_observations(\n",
    "    ctx: RunContext[AgentDeps],\n",
    "    variable_dcid: str,\n",
    "    place_dcid: str,\n",
    "    child_place_type: Optional[str] = None,\n",
    "    date: str = \"latest\",\n",
    ") -> str:\n",
    "    \"\"\"Get observations from Data Commons.\"\"\"\n",
    "    async with DataCommonsMCPClient() as client:\n",
    "        await client.initialize()\n",
    "        args: Dict[str, Any] = {\n",
    "            \"variable_dcid\": variable_dcid,\n",
    "            \"place_dcid\": place_dcid,\n",
    "            \"date\": date,\n",
    "        }\n",
    "        if child_place_type:\n",
    "            args[\"child_place_type\"] = child_place_type\n",
    "        return await client.call_tool(\"get_observations\", args)\n",
    "\n",
    "def create_datacommons_agent() -> Agent:\n",
    "    \"\"\"Create Data Commons agent.\"\"\"\n",
    "    model = OpenAIChatModel(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "    agent = Agent(\n",
    "        model=model,\n",
    "        deps_type=AgentDeps,\n",
    "        system_prompt=\"\"\"You are a precise data analyst using Google Data Commons.\n",
    "\n",
    "Rules:\n",
    "1. Always qualify place names: \"San Diego, CA, USA\"\n",
    "2. Use `search_indicators` → find `variable_dcid`\n",
    "3. Then `get_observations` with that DCID\n",
    "4. For counties/states: sample 5 diverse places first\n",
    "5. Use `date=\"latest\"` unless specified\n",
    "6. Cite source\n",
    "\"\"\",\n",
    "        tools=[search_indicators, get_observations],\n",
    "    )\n",
    "    return agent\n",
    "\n",
    "async def run_dc_query(agent: Agent, query: str, deps: AgentDeps, verbose: bool = False) -> str:\n",
    "    \"\"\"Run a query against Data Commons agent.\"\"\"\n",
    "    if verbose:\n",
    "        print(f\"DC Query: {query}\")\n",
    "    \n",
    "    try:\n",
    "        result = await agent.run(query, deps=deps)\n",
    "        resp = result.output\n",
    "        if verbose:\n",
    "            print(f\"DC Response: {resp}\")\n",
    "        return resp\n",
    "    except Exception as e:\n",
    "        msg = f\"Data Commons agent error: {e}\"\n",
    "        if verbose:\n",
    "            print(msg)\n",
    "        return msg\n",
    "\n",
    "# Create Data Commons agent\n",
    "dc_agent = create_datacommons_agent()\n",
    "dc_deps = AgentDeps(\n",
    "    llm_api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    dc_api_key=os.getenv('DC_API_KEY')\n",
    ")\n",
    "print(\"✓ Data Commons Agent created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c881a8-f87f-47a3-a95a-bb147440ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parallel Agent Coordination System - Complete Replacement\n",
    "Drop-in replacement for EnhancedCoordinatedAgentSystem\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, Any, List\n",
    "import asyncio\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "@dataclass\n",
    "class ParallelContext:\n",
    "    \"\"\"Context for the parallel evaluator agent.\"\"\"\n",
    "    question: str\n",
    "    agent_responses: List[Dict[str, Any]]\n",
    "\n",
    "class ParallelCoordinatedSystem:\n",
    "    \"\"\"\n",
    "    Parallel execution system - queries all agents concurrently,\n",
    "    then intelligently combines results.\n",
    "    \n",
    "    This replaces EnhancedCoordinatedAgentSystem with a more robust approach.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, clm_agent, dc_agent, dc_deps, model_name: str = \"openai\"):\n",
    "        \"\"\"\n",
    "        Initialize parallel coordination system.\n",
    "        \n",
    "        Args:\n",
    "            clm_agent: CLM agent instance\n",
    "            dc_agent: DC agent instance  \n",
    "            dc_deps: Dependencies for DC agent\n",
    "            model_name: Model to use (\"openai\" or \"nrp\")\n",
    "        \"\"\"\n",
    "        self.clm_agent = clm_agent\n",
    "        self.dc_agent = dc_agent\n",
    "        self.dc_deps = dc_deps\n",
    "        self.model_name = model_name\n",
    "        self.conversation_history = []\n",
    "        self.evaluator = self._create_evaluator(model_name)\n",
    "    \n",
    "    def _create_evaluator(self, model_name: str) -> Agent:\n",
    "        \"\"\"\n",
    "        Create evaluator agent that combines responses from multiple agents.\n",
    "        Much simpler than trying to route beforehand!\n",
    "        \"\"\"\n",
    "        \n",
    "        if model_name == \"nrp\":\n",
    "            os.environ['OPENAI_BASE_URL'] = 'https://ellm.nrp-nautilus.io/v1'\n",
    "            os.environ['OPENAI_API_KEY'] = os.getenv('NRP_API_KEY', '')\n",
    "            model_config = 'openai:qwen3'\n",
    "        else:\n",
    "            if 'OPENAI_BASE_URL' in os.environ:\n",
    "                del os.environ['OPENAI_BASE_URL']\n",
    "            model_config = 'openai:gpt-4o-mini'\n",
    "        \n",
    "        evaluator = Agent(\n",
    "            model=model_config,\n",
    "            deps_type=ParallelContext,\n",
    "            system_prompt=\"\"\"You are a response evaluator for a multi-agent system.\n",
    "\n",
    "You receive a question and responses from multiple specialized agents.\n",
    "\n",
    "**Agent Capabilities:**\n",
    "\n",
    "**CLM Agent**: \n",
    "- California landscape/environmental data (30m x 30m resolution)\n",
    "- 189 datasets: air quality, biodiversity, carbon, fire, water, poverty, unemployment\n",
    "- Provides: county statistics, spatial distributions, maps, threshold analysis\n",
    "- Data format: Each value represents a 30m x 30m grid/pixel, NOT individual people\n",
    "- For California ONLY\n",
    "\n",
    "**DC Agent**:\n",
    "- Global demographic/economic/social data\n",
    "- Any location worldwide\n",
    "- Provides: aggregated totals, population counts, overall percentages\n",
    "- Data format: Total counts of people, aggregate statistics\n",
    "- Single aggregated value per region\n",
    "\n",
    "**CRITICAL DATA INTERPRETATION:**\n",
    "\n",
    "**CLM distributions** (e.g., unemployment, poverty):\n",
    "- Shows spatial patterns of RATES across geographic area\n",
    "- Each value = one 30m x 30m PIXEL/GRID, NOT individual people\n",
    "- Statistics are SPATIAL averages (mean across pixels), NOT population-weighted\n",
    "- Example: \"Average unemployment 56.9%\" means the mean rate across all pixels\n",
    "  - This is NOT the actual unemployment rate for the county\n",
    "  - A pixel in a desert (1 person, 100% unemployed) counts the same as a pixel in a city (10,000 people, 0% unemployed)\n",
    "  - This shows geographic spread, not demographic reality\n",
    "- Distribution counts: \"0-10%: 473,178\" = 473,178 pixels have 0-10% unemployment rate\n",
    "- NEVER say \"individuals\" or \"people\" - always say \"pixels\" or \"grids\" or \"30m x 30m areas\"\n",
    "- ALWAYS mention the dataset name/title when reporting CLM data\n",
    "- ALWAYS clarify that CLM statistics are spatial averages, not population totals\n",
    "\n",
    "**DC data**:\n",
    "- Shows actual population counts and totals\n",
    "- \"36,980 unemployed\" means 36,980 actual people\n",
    "- Unemployment rate is the actual demographic rate for the population\n",
    "- Can say \"individuals\" or \"people\" for DC data\n",
    "\n",
    "**Your Task:**\n",
    "1. Identify which agent(s) provided useful, data-backed responses\n",
    "2. Detect failed responses: \"unable to find\", \"no data\", \"error\", vague answers\n",
    "3. Combine or select the best response(s)\n",
    "4. **CRITICALLY**: \n",
    "   - Rewrite CLM responses to use correct terminology\n",
    "   - Always include CLM dataset name\n",
    "   - Explain that CLM provides spatial patterns, not population rates\n",
    "   - Make clear distinction between spatial average and demographic rate\n",
    "\n",
    "**Question Type Analysis:**\n",
    "- \"unemployment in [place]\" → Both agents can answer (DC=actual rate, CLM=spatial pattern)\n",
    "- \"unemployment distribution\" → PREFER CLM (spatial analysis capability)\n",
    "- \"how many unemployed\" → PREFER DC (population counts)\n",
    "- \"which counties have highest\" → PREFER CLM (county comparisons)\n",
    "- Questions about California topics in CLM's 189 datasets → PREFER CLM for spatial analysis\n",
    "\n",
    "**Response Format (JSON):**\n",
    "{\n",
    "    \"selected_agents\": [\"clm\", \"dc\"],\n",
    "    \"strategy\": \"use_clm\" | \"use_dc\" | \"combine_both\" | \"prefer_clm\" | \"prefer_dc\",\n",
    "    \"reasoning\": \"brief explanation\",\n",
    "    \"combined_response\": \"your final answer - MUST include dataset name and clarify spatial vs demographic\"\n",
    "}\n",
    "\n",
    "**Strategy Guidelines:**\n",
    "- \"use_clm\": Only CLM provided useful data OR question specifically asks for distribution/spatial analysis\n",
    "- \"use_dc\": Only DC provided useful data OR question asks for total counts/actual rates\n",
    "- \"combine_both\": Both provide complementary info (CLM=spatial pattern, DC=actual rate/totals)\n",
    "- \"prefer_clm\": Question asks for spatial patterns, distributions, or geographic variation\n",
    "- \"prefer_dc\": Question asks for actual unemployment rate or population counts\n",
    "\n",
    "**Example Response Formats:**\n",
    "\n",
    "For \"unemployment in San Diego\":\n",
    "WRONG: \"Average unemployment is 56.9%\"\n",
    "RIGHT: \"Using the CLM 'Unemployment' dataset, the spatial average across 30m pixels in San Diego County is 56.9%. This represents the geographic spread of unemployment rates, not the actual county unemployment rate. The actual unemployment rate (from DC/BLS) is 4.9% as of August 2025.\"\n",
    "\n",
    "For \"distribution of unemployment\":\n",
    "WRONG: \"0-10%: 473,178 individuals\"  \n",
    "RIGHT: \"Using the CLM 'Unemployment' dataset, the spatial distribution shows:\n",
    "- 0-10% unemployment rate: 473,178 pixels (30m x 30m grid cells)\n",
    "- 10-20%: 818,158 pixels\n",
    "This shows where geographically unemployment rates are high or low, not population counts.\"\n",
    "\n",
    "**Important Rules:**\n",
    "1. ALWAYS mention CLM dataset name (e.g., \"CLM 'Unemployment' dataset\", \"CLM 'Poverty' dataset\")\n",
    "2. ALWAYS clarify spatial average vs population rate when combining CLM and DC\n",
    "3. If question asks \"distribution\" → PREFER CLM (spatial analysis)\n",
    "4. If question asks \"rate\" without \"distribution\" → PREFER DC (actual demographic rate)\n",
    "5. When using CLM data, explain it shows geographic patterns, not demographic totals\n",
    "\"\"\"\n",
    "        )\n",
    "        return evaluator\n",
    "    \n",
    "    def _build_history_context(self) -> str:\n",
    "        \"\"\"Build a summary of recent conversation history.\"\"\"\n",
    "        if not self.conversation_history:\n",
    "            return \"\"\n",
    "        \n",
    "        # Get last 3 interactions for context\n",
    "        recent = self.conversation_history[-3:]\n",
    "        context_lines = []\n",
    "        for entry in recent:\n",
    "            context_lines.append(f\"Q: {entry['question']}\")\n",
    "            # Truncate long responses\n",
    "            response = entry.get('final_response', '')\n",
    "            if response and len(response) > 150:\n",
    "                response = response[:150] + \"...\"\n",
    "            context_lines.append(f\"A: {response}\\n\")\n",
    "        \n",
    "        return \"Recent conversation:\\n\" + \"\\n\".join(context_lines)\n",
    "    \n",
    "    def _enhance_question_with_context(self, question: str) -> str:\n",
    "        \"\"\"\n",
    "        Enhance follow-up questions with context from conversation history.\n",
    "        \n",
    "        Examples:\n",
    "        - \"What about Los Angeles?\" → \"What is the population of Los Angeles, CA, USA?\"\n",
    "        - \"How about San Diego?\" → \"What is the carbon turnover time in San Diego?\"\n",
    "        \"\"\"\n",
    "        # Check if this looks like a follow-up question\n",
    "        follow_up_patterns = [\n",
    "            r'^(what about|how about|and|also)\\s+',\n",
    "            r'^\\w+\\s+(too|also)\\??$',\n",
    "            r'^(there|that)\\??$'\n",
    "        ]\n",
    "        \n",
    "        is_follow_up = any(re.search(pattern, question.lower()) for pattern in follow_up_patterns)\n",
    "        \n",
    "        if not is_follow_up or not self.conversation_history:\n",
    "            return question\n",
    "        \n",
    "        # Get the last question to understand context\n",
    "        last_entry = self.conversation_history[-1]\n",
    "        last_question = last_entry['question']\n",
    "        \n",
    "        # Extract the topic/metric from the last question\n",
    "        context_hint = \"\"\n",
    "        \n",
    "        # Common patterns to extract\n",
    "        if 'population' in last_question.lower():\n",
    "            context_hint = \"population of\"\n",
    "        elif 'income' in last_question.lower() or 'median household income' in last_question.lower():\n",
    "            context_hint = \"median household income in\"\n",
    "        elif 'carbon' in last_question.lower():\n",
    "            context_hint = \"carbon turnover time in\"\n",
    "        elif 'burn' in last_question.lower() or 'fire' in last_question.lower():\n",
    "            context_hint = \"burn probability in\"\n",
    "        elif 'unemployment' in last_question.lower():\n",
    "            context_hint = \"unemployment rate in\"\n",
    "        elif 'crime' in last_question.lower():\n",
    "            context_hint = \"crime rate in\"\n",
    "        elif 'poverty' in last_question.lower():\n",
    "            context_hint = \"poverty rate in\"\n",
    "        \n",
    "        # Extract location from new question\n",
    "        # Remove common follow-up words\n",
    "        clean_question = re.sub(r'^(what about|how about|and|also)\\s+', '', question, flags=re.IGNORECASE).strip()\n",
    "        \n",
    "        if context_hint and clean_question:\n",
    "            # Add proper location qualifier for Data Commons\n",
    "            if not any(suffix in clean_question.lower() for suffix in [', ca', ', usa', 'california']):\n",
    "                # Assume California city if not specified\n",
    "                clean_question = f\"{clean_question}, CA, USA\"\n",
    "            enhanced = f\"What is the {context_hint} {clean_question}?\"\n",
    "            return enhanced\n",
    "        \n",
    "        return question\n",
    "    \n",
    "    async def _query_clm_safe(self, question: str, timeout: int = 120) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Query CLM agent with error handling.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from dataclasses import dataclass as dc\n",
    "            \n",
    "            @dc\n",
    "            class AgentContext:\n",
    "                current_coverage_id: Optional[str] = None\n",
    "                current_dataset_info: Optional[dict] = None\n",
    "            \n",
    "            ctx = AgentContext()\n",
    "            \n",
    "            result = await asyncio.wait_for(\n",
    "                self.clm_agent.run(question, timeout=timeout, deps=ctx),\n",
    "                timeout=timeout + 5\n",
    "            )\n",
    "            \n",
    "            output = result.get('output', '')\n",
    "            \n",
    "            # Check for failure indicators\n",
    "            if isinstance(output, str):\n",
    "                failure_indicators = [\n",
    "                    'unable to find',\n",
    "                    'no data',\n",
    "                    'could not find',\n",
    "                    'no suitable datasets',\n",
    "                    'error:',\n",
    "                    'cannot answer',\n",
    "                    'no dataset selected'\n",
    "                ]\n",
    "                is_failure = any(indicator in output.lower() for indicator in failure_indicators)\n",
    "                \n",
    "                # CRITICAL: Pass through ALL data from CLM agent, including distribution_data\n",
    "                return {\n",
    "                    'agent_name': 'clm',\n",
    "                    'success': not is_failure,\n",
    "                    'response': result,  # Keep the full result object\n",
    "                    'output': output,\n",
    "                    'map_data': result.get('map_data'),\n",
    "                    'distribution_data': result.get('distribution_data'),  # Pass through distribution data\n",
    "                    'error': None\n",
    "                }\n",
    "            \n",
    "            # CRITICAL: Pass through ALL data from CLM agent\n",
    "            return {\n",
    "                'agent_name': 'clm',\n",
    "                'success': True,\n",
    "                'response': result,  # Keep the full result object\n",
    "                'output': output,\n",
    "                'map_data': result.get('map_data'),\n",
    "                'distribution_data': result.get('distribution_data'),  # Pass through distribution data\n",
    "                'error': None\n",
    "            }\n",
    "            \n",
    "        except asyncio.TimeoutError:\n",
    "            return {\n",
    "                'agent_name': 'clm',\n",
    "                'success': False,\n",
    "                'response': None,\n",
    "                'output': f\"CLM agent timed out after {timeout} seconds\",\n",
    "                'map_data': None,\n",
    "                'distribution_data': None,\n",
    "                'error': 'timeout'\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'agent_name': 'clm',\n",
    "                'success': False,\n",
    "                'response': None,\n",
    "                'output': f\"CLM agent error: {str(e)}\",\n",
    "                'map_data': None,\n",
    "                'distribution_data': None,\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    async def _query_dc_safe(self, question: str, timeout: int = 120) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Query DC agent with error handling.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Import the run_dc_query function (assumes it's in scope)\n",
    "            dc_result = await asyncio.wait_for(\n",
    "                run_dc_query(self.dc_agent, question, self.dc_deps, verbose=False),\n",
    "                timeout=timeout\n",
    "            )\n",
    "            \n",
    "            # Check for failure indicators\n",
    "            if isinstance(dc_result, str):\n",
    "                failure_indicators = [\n",
    "                    'unable to find',\n",
    "                    'no data',\n",
    "                    'could not find',\n",
    "                    'returned no current observations',\n",
    "                    'error',\n",
    "                    'cannot answer'\n",
    "                ]\n",
    "                is_failure = any(indicator in dc_result.lower() for indicator in failure_indicators)\n",
    "                \n",
    "                return {\n",
    "                    'agent_name': 'dc',\n",
    "                    'success': not is_failure,\n",
    "                    'response': None,\n",
    "                    'output': dc_result,\n",
    "                    'error': None\n",
    "                }\n",
    "            \n",
    "            return {\n",
    "                'agent_name': 'dc',\n",
    "                'success': True,\n",
    "                'response': None,\n",
    "                'output': str(dc_result),\n",
    "                'error': None\n",
    "            }\n",
    "            \n",
    "        except asyncio.TimeoutError:\n",
    "            return {\n",
    "                'agent_name': 'dc',\n",
    "                'success': False,\n",
    "                'response': None,\n",
    "                'output': f\"DC agent timed out after {timeout} seconds\",\n",
    "                'error': 'timeout'\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'agent_name': 'dc',\n",
    "                'success': False,\n",
    "                'response': None,\n",
    "                'output': f\"DC agent error: {str(e)}\",\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    async def run(self, question: str, timeout: int = 120) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Query all agents in parallel and intelligently combine results.\n",
    "        \n",
    "        Args:\n",
    "            question: User's question\n",
    "            timeout: Timeout per agent in seconds\n",
    "            \n",
    "        Returns:\n",
    "            Dict with output, map_data, distribution_data, and metadata\n",
    "        \"\"\"\n",
    "        \n",
    "        # Build history context\n",
    "        history_context = self._build_history_context()\n",
    "        \n",
    "        # Enhance follow-up questions\n",
    "        enhanced_question = self._enhance_question_with_context(question)\n",
    "        \n",
    "        if enhanced_question != question:\n",
    "            print(f\"📝 Enhanced question: {enhanced_question}\")\n",
    "        \n",
    "        print(f\"🔄 Querying CLM and DC agents in parallel...\")\n",
    "        \n",
    "        # Query both agents concurrently\n",
    "        clm_task = self._query_clm_safe(question, timeout)  # Use original for CLM\n",
    "        dc_task = self._query_dc_safe(enhanced_question, timeout)  # Use enhanced for DC\n",
    "        \n",
    "        agent_results = await asyncio.gather(clm_task, dc_task)\n",
    "        \n",
    "        # Show what each agent returned\n",
    "        for result in agent_results:\n",
    "            status = \"✓\" if result['success'] else \"✗\"\n",
    "            output_preview = result['output'][:100] if result['output'] else \"No output\"\n",
    "            print(f\"  {status} {result['agent_name'].upper()}: {output_preview}...\")\n",
    "        \n",
    "        # Build evaluation context\n",
    "        eval_input = f\"\"\"Question: {question}\n",
    "\n",
    "Agent Responses:\n",
    "\n",
    "**CLM Agent:**\n",
    "Success: {agent_results[0]['success']}\n",
    "Response: {agent_results[0]['output']}\n",
    "\n",
    "**DC Agent:**\n",
    "Success: {agent_results[1]['success']}\n",
    "Response: {agent_results[1]['output']}\n",
    "\n",
    "Based on these responses, evaluate which agent(s) successfully answered the question and provide a combined response.\n",
    "\"\"\"\n",
    "        \n",
    "        # Evaluate and combine responses\n",
    "        try:\n",
    "            eval_result = await self.evaluator.run(\n",
    "                eval_input,\n",
    "                deps=ParallelContext(question=question, agent_responses=agent_results)\n",
    "            )\n",
    "            \n",
    "            eval_output = eval_result.output if hasattr(eval_result, 'output') else str(eval_result)\n",
    "            \n",
    "            # Parse JSON from evaluation\n",
    "            json_match = re.search(r'\\{[^}]+\\}', eval_output, re.DOTALL)\n",
    "            if json_match:\n",
    "                evaluation = json.loads(json_match.group())\n",
    "            else:\n",
    "                # Fallback: use first successful response\n",
    "                successful = [r for r in agent_results if r['success']]\n",
    "                if successful:\n",
    "                    evaluation = {\n",
    "                        'selected_agents': [successful[0]['agent_name']],\n",
    "                        'strategy': f\"use_{successful[0]['agent_name']}\",\n",
    "                        'reasoning': 'Fallback: using first successful response',\n",
    "                        'combined_response': successful[0]['output']\n",
    "                    }\n",
    "                else:\n",
    "                    evaluation = {\n",
    "                        'selected_agents': [],\n",
    "                        'strategy': 'none',\n",
    "                        'reasoning': 'No agent provided useful response',\n",
    "                        'combined_response': 'I could not find information to answer this question. Both agents were unable to retrieve relevant data.'\n",
    "                    }\n",
    "            \n",
    "            print(f\"📊 Strategy: {evaluation['strategy']}\")\n",
    "            print(f\"   Selected: {', '.join(evaluation['selected_agents'])}\")\n",
    "            print(f\"   Reasoning: {evaluation['reasoning']}\")\n",
    "            \n",
    "            # Collect map and distribution data from successful agents\n",
    "            # CRITICAL: Don't filter by success - get data from ANY agent that has it\n",
    "            map_data = None\n",
    "            distribution_data = None\n",
    "            \n",
    "            for result in agent_results:\n",
    "                # Get map_data from any agent that has it\n",
    "                if result.get('map_data'):\n",
    "                    map_data = result['map_data']\n",
    "                    print(f\"  Found map_data from {result['agent_name']}\")\n",
    "                \n",
    "                # Get distribution_data from any agent that has it\n",
    "                if result.get('distribution_data'):\n",
    "                    dist = result['distribution_data']\n",
    "                    # Always take the distribution with the most data points\n",
    "                    if distribution_data is None or len(dist.get('data', [])) > len(distribution_data.get('data', [])):\n",
    "                        distribution_data = dist\n",
    "                        print(f\"  Found distribution_data from {result['agent_name']} with {len(dist.get('data', []))} data points\")\n",
    "            \n",
    "            # Debug: Print what we collected\n",
    "            if distribution_data:\n",
    "                print(f\"  Final distribution_data has {len(distribution_data.get('data', []))} data points\")\n",
    "                # Check how many unique counties\n",
    "                if 'data' in distribution_data:\n",
    "                    counties_in_dist = set([d.get('name') for d in distribution_data['data'] if 'name' in d])\n",
    "                    print(f\"  Counties in distribution: {counties_in_dist}\")\n",
    "            else:\n",
    "                print(\"  No distribution_data collected\")\n",
    "            \n",
    "            # Store in history\n",
    "            self.conversation_history.append({\n",
    "                'question': question,\n",
    "                'enhanced_question': enhanced_question if enhanced_question != question else None,\n",
    "                'agent_results': agent_results,\n",
    "                'evaluation': evaluation,\n",
    "                'final_response': evaluation['combined_response']\n",
    "            })\n",
    "            \n",
    "            return {\n",
    "                'output': evaluation['combined_response'],\n",
    "                'map_data': map_data,\n",
    "                'distribution_data': distribution_data,\n",
    "                'routing': {\n",
    "                    'agent': evaluation['strategy'],\n",
    "                    'confidence': 1.0 if evaluation['selected_agents'] else 0.0,\n",
    "                    'reasoning': evaluation['reasoning']\n",
    "                },\n",
    "                'source_agent': evaluation['strategy'],\n",
    "                'evaluation': evaluation,\n",
    "                'all_agent_results': agent_results\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            error_detail = traceback.format_exc()\n",
    "            \n",
    "            # Fallback: return first successful agent response\n",
    "            successful = [r for r in agent_results if r['success']]\n",
    "            if successful:\n",
    "                fallback_output = successful[0]['output']\n",
    "                fallback_agent = successful[0]['agent_name']\n",
    "            else:\n",
    "                fallback_output = f\"Error in evaluation: {str(e)}\\n\\nAgent responses were:\\nCLM: {agent_results[0]['output'][:200]}\\nDC: {agent_results[1]['output'][:200]}\"\n",
    "                fallback_agent = 'error'\n",
    "            \n",
    "            return {\n",
    "                'output': fallback_output,\n",
    "                'map_data': agent_results[0].get('map_data') if agent_results[0]['success'] else None,\n",
    "                'distribution_data': agent_results[0].get('distribution_data') if agent_results[0]['success'] else None,\n",
    "                'routing': {\n",
    "                    'agent': fallback_agent,\n",
    "                    'confidence': 0.5,\n",
    "                    'reasoning': f'Evaluation error, using fallback: {str(e)}'\n",
    "                },\n",
    "                'source_agent': fallback_agent,\n",
    "                'evaluation': None,\n",
    "                'all_agent_results': agent_results\n",
    "            }\n",
    "    \n",
    "    def get_history_summary(self) -> str:\n",
    "        \"\"\"Get a summary of the conversation history.\"\"\"\n",
    "        if not self.conversation_history:\n",
    "            return \"No conversation history yet.\"\n",
    "        \n",
    "        summary = []\n",
    "        for i, entry in enumerate(self.conversation_history, 1):\n",
    "            eval_info = entry.get('evaluation', {})\n",
    "            agents_used = ', '.join(eval_info.get('selected_agents', ['unknown']))\n",
    "            q = entry['question']\n",
    "            if entry.get('enhanced_question'):\n",
    "                q = f\"{q} → {entry['enhanced_question']}\"\n",
    "            summary.append(f\"{i}. [{agents_used.upper()}] {q[:80]}...\")\n",
    "        \n",
    "        return \"\\n\".join(summary)\n",
    "\n",
    "print(\"✓ Parallel coordination system module loaded!\")\n",
    "print(\"✓ Ready to replace EnhancedCoordinatedAgentSystem\")\n",
    "\n",
    "coordinated_system = ParallelCoordinatedSystem(\n",
    "    clm_agent=clm_agent,\n",
    "    dc_agent=dc_agent,\n",
    "    dc_deps=dc_deps,\n",
    "    model_name=MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d813085-6ec7-4990-ad8f-de238d20a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import nest_asyncio\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from fastmcp import Client\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "# Enable nested asyncio for Jupyter\n",
    "nest_asyncio.apply()\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0df824-8dab-42b7-86a2-9cc9ec21c987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Complete Chat Interface for Coordinated Multi-Agent System\n",
    "Cell 6 - Copy this entire code block\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import Javascript, display, clear_output, HTML\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime\n",
    "import folium\n",
    "from folium import WmsTileLayer\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import base64\n",
    "import markdown\n",
    "import html as html_module\n",
    "import asyncio\n",
    "\n",
    "\n",
    "class CoordinatedChatInterface:\n",
    "    \"\"\"Chat interface that works with the coordinated multi-agent system.\"\"\"\n",
    "    \n",
    "    def __init__(self, coordinated_system):\n",
    "        \"\"\"\n",
    "        Initialize chat interface.\n",
    "        \n",
    "        Args:\n",
    "            coordinated_system: ParallelCoordinatedSystem instance\n",
    "        \"\"\"\n",
    "        self.system = coordinated_system\n",
    "        self.messages_container = []\n",
    "        \n",
    "        # Output area\n",
    "        self.output_area = widgets.VBox(\n",
    "            layout=widgets.Layout(\n",
    "                border='1px solid #ddd',\n",
    "                height='calc(100vh - 350px)',\n",
    "                min_height='400px',\n",
    "                overflow_y='auto',\n",
    "                padding='10px',\n",
    "                margin='0 0 10px 0'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Input controls\n",
    "        self.input_box = widgets.Textarea(\n",
    "            placeholder='Ask about California landscape metrics or general data (population, demographics, etc.)...',\n",
    "            layout=widgets.Layout(width='100%', height='100px', margin='10px 0')\n",
    "        )\n",
    "        \n",
    "        self.send_button = widgets.Button(\n",
    "            description='Send',\n",
    "            button_style='primary',\n",
    "            icon='paper-plane',\n",
    "            layout=widgets.Layout(width='100px', margin='0 5px 0 0')\n",
    "        )\n",
    "        \n",
    "        self.clear_button = widgets.Button(\n",
    "            description='Clear',\n",
    "            button_style='warning',\n",
    "            icon='trash',\n",
    "            layout=widgets.Layout(width='100px', margin='0 5px 0 0')\n",
    "        )\n",
    "        \n",
    "        self.history_button = widgets.Button(\n",
    "            description='History',\n",
    "            button_style='info',\n",
    "            icon='list',\n",
    "            layout=widgets.Layout(width='100px', margin='0 5px 0 0')\n",
    "        )\n",
    "        \n",
    "        self.status_label = widgets.HTML(\n",
    "            value=\"✅ Ready\",\n",
    "            layout=widgets.Layout(margin='0 0 0 10px')\n",
    "        )\n",
    "        \n",
    "        # Event handlers\n",
    "        self.send_button.on_click(self.on_send_clicked)\n",
    "        self.clear_button.on_click(self.on_clear_clicked)\n",
    "        self.history_button.on_click(self.on_history_clicked)\n",
    "        \n",
    "        # Layout\n",
    "        button_box = widgets.HBox([\n",
    "            self.send_button,\n",
    "            self.clear_button,\n",
    "            self.history_button,\n",
    "            self.status_label\n",
    "        ])\n",
    "        \n",
    "        self.interface = widgets.VBox([\n",
    "            widgets.HTML(value=\"\"\"\n",
    "                <h3>🤖 Multi-Agent Assistant</h3>\n",
    "                <p style='color: #666; font-size: 0.9em;'>\n",
    "                    <strong>CLM Agent:</strong> California landscape metrics (fire, carbon, vegetation, poverty, unemployment)<br>\n",
    "                    <strong>DC Agent:</strong> Demographics, economics, health data (any location)\n",
    "                </p>\n",
    "            \"\"\"),\n",
    "            self.output_area,\n",
    "            self.input_box,\n",
    "            button_box\n",
    "        ], layout=widgets.Layout(width='100%', max_width='1200px', margin='0 auto'))\n",
    "        \n",
    "        # Welcome message\n",
    "        self._add_message(\n",
    "            \"Welcome! I can help with:\\n\\n\"\n",
    "            \"**California Landscape Metrics (CLM):**\\n\"\n",
    "            \"- Burn probability, carbon turnover, vegetation data\\n\"\n",
    "            \"- Poverty, unemployment (spatial patterns)\\n\"\n",
    "            \"- Maps and visualizations\\n\"\n",
    "            \"- County statistics and comparisons\\n\\n\"\n",
    "            \"**General Data (via Data Commons):**\\n\"\n",
    "            \"- Population, demographics, income\\n\"\n",
    "            \"- Any location worldwide\\n\"\n",
    "            \"- Economic and social indicators\\n\\n\"\n",
    "            \"**Examples:**\\n\"\n",
    "            \"- What is the carbon turnover time in Los Angeles? (CLM)\\n\"\n",
    "            \"- What is the population of San Diego? (Data Commons)\\n\"\n",
    "            \"- Show me a burn probability map for California (CLM)\\n\"\n",
    "            \"- What is the median income in Austin, Texas? (Data Commons)\\n\"\n",
    "            \"- Show distribution of unemployment in San Diego and Los Angeles (CLM)\",\n",
    "            \"system\"\n",
    "        )\n",
    "    \n",
    "    def _get_wms_bounds(self, wms_url, layer_name):\n",
    "        \"\"\"Get WMS layer bounds.\"\"\"\n",
    "        california_bounds = [[32.5, -124.5], [42.0, -114.0]]\n",
    "        try:\n",
    "            import requests\n",
    "            from xml.etree import ElementTree as ET\n",
    "            \n",
    "            params = {\n",
    "                'service': 'WMS',\n",
    "                'version': '1.1.0',\n",
    "                'request': 'GetCapabilities'\n",
    "            }\n",
    "            response = requests.get(wms_url + '/wms', params=params, timeout=10)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                root = ET.fromstring(response.content)\n",
    "                for layer in root.iter('Layer'):\n",
    "                    name_elem = layer.find('Name')\n",
    "                    if name_elem is not None and name_elem.text == layer_name:\n",
    "                        bbox = layer.find('LatLonBoundingBox')\n",
    "                        if bbox is not None:\n",
    "                            minx = float(bbox.get('minx'))\n",
    "                            miny = float(bbox.get('miny'))\n",
    "                            maxx = float(bbox.get('maxx'))\n",
    "                            maxy = float(bbox.get('maxy'))\n",
    "                            return [[miny, minx], [maxy, maxx]]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return california_bounds\n",
    "    \n",
    "    def _get_legend_url(self, wms_url, layer_name, style_name=None):\n",
    "        \"\"\"Generate WMS legend URL.\"\"\"\n",
    "        from urllib.parse import urlencode\n",
    "        \n",
    "        params = {\n",
    "            'service': 'WMS',\n",
    "            'version': '1.1.0',\n",
    "            'request': 'GetLegendGraphic',\n",
    "            'layer': layer_name,\n",
    "            'format': 'image/png',\n",
    "            'width': '20',\n",
    "            'height': '20',\n",
    "            'legend_options': 'fontAntiAliasing:true;fontSize:10;fontName:Arial;dx:5;absoluteMargins:true'\n",
    "        }\n",
    "        \n",
    "        if style_name:\n",
    "            params['style'] = style_name\n",
    "        \n",
    "        return f\"{wms_url}/wms?{urlencode(params)}\"\n",
    "    \n",
    "    def _create_map(self, map_data, style_name=None):\n",
    "        \"\"\"Create Folium map.\"\"\"\n",
    "        try:\n",
    "            wms_url = map_data.get('wms_base_url', '')\n",
    "            layer_name = map_data.get('wms_layer_name', '')\n",
    "            title = map_data.get('title', 'Dataset')\n",
    "            \n",
    "            bounds = self._get_wms_bounds(wms_url, layer_name)\n",
    "            center_lat = (bounds[0][0] + bounds[1][0]) / 2\n",
    "            center_lon = (bounds[0][1] + bounds[1][1]) / 2\n",
    "            \n",
    "            m = folium.Map(\n",
    "                location=[center_lat, center_lon],\n",
    "                tiles='OpenStreetMap',\n",
    "                control_scale=True\n",
    "            )\n",
    "            m.fit_bounds(bounds)\n",
    "            \n",
    "            if wms_url and layer_name:\n",
    "                wms_params = {\n",
    "                    'url': wms_url + '/wms',\n",
    "                    'layers': layer_name,\n",
    "                    'name': title,\n",
    "                    'fmt': 'image/png',\n",
    "                    'transparent': True,\n",
    "                    'overlay': True,\n",
    "                    'control': True,\n",
    "                    'version': '1.1.0'\n",
    "                }\n",
    "                \n",
    "                if style_name:\n",
    "                    wms_params['styles'] = style_name\n",
    "                \n",
    "                wms = WmsTileLayer(**wms_params)\n",
    "                wms.add_to(m)\n",
    "                folium.LayerControl().add_to(m)\n",
    "                \n",
    "                legend_url = self._get_legend_url(wms_url, layer_name, style_name)\n",
    "                units = map_data.get('units', '')\n",
    "                unit_text = f'<p style=\"margin: 5px 0 0 0; font-size: 11px; color: #333; text-align: center;\">Units: {units}</p>' if units else ''\n",
    "                \n",
    "                legend_html = f'''\n",
    "                <div style=\"position: fixed; top: 10px; right: 10px; background-color: white; \n",
    "                            z-index: 9999; padding: 10px; border: 2px solid grey; border-radius: 5px; \n",
    "                            box-shadow: 2px 2px 6px rgba(0,0,0,0.3);\">\n",
    "                    <img src=\"{legend_url}\" alt=\"Legend\" style=\"display: block;\">\n",
    "                    {unit_text}\n",
    "                </div>\n",
    "                '''\n",
    "                m.get_root().html.add_child(folium.Element(legend_html))\n",
    "            \n",
    "            return m\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating map: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _create_distribution_chart(self, distribution_data):\n",
    "        \"\"\"Create distribution chart - FIXED to show all counties.\"\"\"\n",
    "        try:\n",
    "            data = distribution_data.get('data', [])\n",
    "            dist_type = distribution_data.get('distribution_type', 'continuous')\n",
    "            dataset_info = distribution_data.get('dataset_info', {})\n",
    "            title = dataset_info.get('title', 'Value Distribution')\n",
    "            units = dataset_info.get('units', '')\n",
    "            filter_column = 'name'  # Column name for county identifier\n",
    "            \n",
    "            if not data:\n",
    "                print(\"No distribution data to plot\")\n",
    "                return None\n",
    "            \n",
    "            # Debug: Print data structure\n",
    "            print(f\"Distribution data type: {dist_type}\")\n",
    "            print(f\"Number of data points: {len(data)}\")\n",
    "            print(f\"Sample data point: {data[0] if data else 'None'}\")\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(12, 6), dpi=100)\n",
    "            \n",
    "            # Get unique counties from the data\n",
    "            counties = sorted(list(set([d.get(filter_column) for d in data if filter_column in d])))\n",
    "            \n",
    "            if not counties:\n",
    "                print(\"No counties found in data\")\n",
    "                return None\n",
    "            \n",
    "            print(f\"Counties found: {counties}\")\n",
    "            \n",
    "            # Use distinct colors for each county\n",
    "            colors = plt.cm.tab10(range(len(counties)))\n",
    "            \n",
    "            if dist_type == 'categorical':\n",
    "                import numpy as np\n",
    "                # Get all unique values across all counties\n",
    "                values = sorted(list(set([d['value'] for d in data])))\n",
    "                x = np.arange(len(values))\n",
    "                width = 0.8 / len(counties) if len(counties) > 1 else 0.5\n",
    "                \n",
    "                for i, county in enumerate(counties):\n",
    "                    county_data = [d for d in data if d.get(filter_column) == county]\n",
    "                    counts = []\n",
    "                    for val in values:\n",
    "                        matching = [d['count'] for d in county_data if d['value'] == val]\n",
    "                        counts.append(matching[0] if matching else 0)\n",
    "                    \n",
    "                    offset = (i - len(counties)/2) * width + width/2\n",
    "                    ax.bar(x + offset, counts, width, label=county, alpha=0.7, color=colors[i])\n",
    "                \n",
    "                ax.set_xlabel('Value', fontsize=11)\n",
    "                ax.set_ylabel('Count (pixels)', fontsize=11)\n",
    "                ax.set_xticks(x)\n",
    "                ax.set_xticklabels([str(v) for v in values])\n",
    "                ax.legend(fontsize=10, loc='best')\n",
    "                ax.set_title(f'{title}\\nCategorical Distribution', fontsize=12, fontweight='bold', pad=10)\n",
    "                \n",
    "            else:  # continuous\n",
    "                bins = distribution_data.get('bins', [])\n",
    "                if not bins:\n",
    "                    print(\"No bins found in distribution data\")\n",
    "                    return None\n",
    "                \n",
    "                print(f\"Bins: {bins}\")\n",
    "                \n",
    "                # Calculate bin centers for x-axis positioning\n",
    "                bin_centers = [(bins[i] + bins[i+1]) / 2 for i in range(len(bins)-1)]\n",
    "                bin_width = bins[1] - bins[0] if len(bins) > 1 else 1\n",
    "                \n",
    "                # Adjust bar width based on number of counties\n",
    "                bar_width = bin_width * 0.8 / len(counties) if len(counties) > 1 else bin_width * 0.7\n",
    "                \n",
    "                for i, county in enumerate(counties):\n",
    "                    # Get data for this county\n",
    "                    county_data = [d for d in data if d.get(filter_column) == county]\n",
    "                    \n",
    "                    # Sort by bin_index to ensure correct order\n",
    "                    county_data = sorted(county_data, key=lambda x: x.get('bin_index', 0))\n",
    "                    \n",
    "                    print(f\"County {county}: {len(county_data)} data points\")\n",
    "                    \n",
    "                    # Extract counts\n",
    "                    counts = [d['count'] for d in county_data]\n",
    "                    \n",
    "                    # Calculate bar positions\n",
    "                    if len(counties) > 1:\n",
    "                        # Offset bars for multiple counties\n",
    "                        offset = (i - len(counties)/2) * bar_width + bar_width/2\n",
    "                        positions = [bc + offset for bc in bin_centers]\n",
    "                    else:\n",
    "                        # Center bars for single county\n",
    "                        positions = bin_centers\n",
    "                    \n",
    "                    # Plot bars\n",
    "                    ax.bar(positions, counts, bar_width, label=county, alpha=0.7, color=colors[i])\n",
    "                \n",
    "                # Set labels\n",
    "                xlabel = f'Value Range ({units})' if units else 'Value Range'\n",
    "                ax.set_xlabel(xlabel, fontsize=11)\n",
    "                ax.set_ylabel('Count (pixels)', fontsize=11)\n",
    "                \n",
    "                # Add legend if multiple counties\n",
    "                if len(counties) > 1:\n",
    "                    ax.legend(fontsize=10, loc='best')\n",
    "                \n",
    "                ax.set_title(f'{title}\\nValue Distribution', fontsize=12, fontweight='bold', pad=10)\n",
    "            \n",
    "            ax.grid(True, alpha=0.3, linestyle='--')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save to buffer\n",
    "            buf = io.BytesIO()\n",
    "            plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')\n",
    "            buf.seek(0)\n",
    "            img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
    "            plt.close(fig)\n",
    "            \n",
    "            print(f\"Chart created successfully with {len(counties)} counties\")\n",
    "            return img_base64\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating chart: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "    \n",
    "    def _add_message(self, text, role=\"user\", map_data=None, distribution_data=None, routing_info=None):\n",
    "        \"\"\"Add message to chat.\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        if role == \"user\":\n",
    "            color = \"#007bff\"\n",
    "            icon = \"👤\"\n",
    "            label = \"You\"\n",
    "            bg_color = \"#e7f3ff\"\n",
    "        elif role == \"assistant\":\n",
    "            color = \"#28a745\"\n",
    "            icon = \"🤖\"\n",
    "            label = \"Assistant\"\n",
    "            bg_color = \"#e8f5e9\"\n",
    "        else:\n",
    "            color = \"#6c757d\"\n",
    "            icon = \"ℹ️\"\n",
    "            label = \"System\"\n",
    "            bg_color = \"#f8f9fa\"\n",
    "        \n",
    "        # Add routing badge if available\n",
    "        routing_badge = \"\"\n",
    "        if routing_info:\n",
    "            agent = routing_info.get('agent', 'unknown').upper()\n",
    "            confidence = routing_info.get('confidence', 0)\n",
    "            agent_colors = {\n",
    "                'CLM': '#ff6b6b',\n",
    "                'DC': '#4ecdc4',\n",
    "                'BOTH': '#95e1d3',\n",
    "                'USE_CLM': '#ff6b6b',\n",
    "                'USE_DC': '#4ecdc4',\n",
    "                'COMBINE_BOTH': '#95e1d3',\n",
    "                'PREFER_CLM': '#ff9999',\n",
    "                'PREFER_DC': '#7dd3c0'\n",
    "            }\n",
    "            badge_color = agent_colors.get(agent, '#999')\n",
    "            routing_badge = f\"\"\"\n",
    "                <span style='background-color: {badge_color}; color: white; padding: 2px 8px; \n",
    "                             border-radius: 12px; font-size: 0.75em; font-weight: bold; margin-left: 8px;'>\n",
    "                    {agent} ({confidence:.0%})\n",
    "                </span>\n",
    "            \"\"\"\n",
    "        \n",
    "        # Convert markdown for assistant\n",
    "        if role == \"assistant\":\n",
    "            try:\n",
    "                html_content = markdown.markdown(str(text), extensions=['extra', 'nl2br', 'sane_lists'])\n",
    "            except:\n",
    "                html_content = html_module.escape(str(text)).replace('\\n', '<br>')\n",
    "        else:\n",
    "            html_content = html_module.escape(str(text)).replace('\\n', '<br>')\n",
    "        \n",
    "        message_html = widgets.HTML(\n",
    "            value=f\"\"\"\n",
    "            <div style='margin: 10px 0; padding: 12px; background-color: {bg_color}; \n",
    "                        border-radius: 8px; border-left: 4px solid {color}; box-shadow: 0 1px 3px rgba(0,0,0,0.1);'>\n",
    "                <div style='display: flex; justify-content: space-between; margin-bottom: 8px;'>\n",
    "                    <div>\n",
    "                        <strong style='color: {color};'>{icon} {label}</strong>\n",
    "                        {routing_badge}\n",
    "                    </div>\n",
    "                    <span style='color: #999; font-size: 0.85em;'>{timestamp}</span>\n",
    "                </div>\n",
    "                <div style='line-height: 1.6;'>{html_content}</div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        self.messages_container.append(message_html)\n",
    "        \n",
    "        # Add visualizations\n",
    "        if distribution_data:\n",
    "            img_base64 = self._create_distribution_chart(distribution_data)\n",
    "            if img_base64:\n",
    "                chart_html = f\"\"\"\n",
    "                <div style='width: 98%; margin: 10px 0;'>\n",
    "                    <div style='width: 100%; border: 1px solid #ddd; border-radius: 8px; \n",
    "                                padding: 10px; background-color: white;'>\n",
    "                        <img src=\"data:image/png;base64,{img_base64}\" \n",
    "                             style=\"width: 100%; height: auto;\" alt=\"Distribution Chart\">\n",
    "                    </div>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                self.messages_container.append(widgets.HTML(value=chart_html))\n",
    "        \n",
    "        elif map_data:\n",
    "            layer_name = map_data.get('wms_layer_name', '')\n",
    "            style_name = f\"{layer_name}_std\" if layer_name else None\n",
    "            folium_map = self._create_map(map_data, style_name=style_name)\n",
    "            \n",
    "            if folium_map:\n",
    "                map_html = f\"\"\"\n",
    "                <div style='width: 98%; margin: 10px 0;'>\n",
    "                    <div style='width: 100%; height: 300px; border: 1px solid #ddd; \n",
    "                                border-radius: 8px; overflow: hidden;'>\n",
    "                        {folium_map._repr_html_()}\n",
    "                    </div>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                self.messages_container.append(widgets.HTML(value=map_html))\n",
    "        \n",
    "        self.output_area.children = tuple(self.messages_container)\n",
    "    \n",
    "    def on_send_clicked(self, button):\n",
    "        \"\"\"Handle send button click.\"\"\"\n",
    "        question = self.input_box.value.strip()\n",
    "        if not question:\n",
    "            return\n",
    "        \n",
    "        self._add_message(question, \"user\")\n",
    "        self.input_box.value = \"\"\n",
    "        self.send_button.disabled = True\n",
    "        self.input_box.disabled = True\n",
    "        self.status_label.value = \"<span style='color: orange;'>⏳ Processing...</span>\"\n",
    "        \n",
    "        try:\n",
    "            result = asyncio.get_event_loop().run_until_complete(\n",
    "                asyncio.wait_for(self.system.run(question), timeout=180)\n",
    "            )\n",
    "            \n",
    "            answer = result.get('output', 'No response')\n",
    "            routing_info = result.get('routing')\n",
    "            map_data = result.get('map_data')\n",
    "            distribution_data = result.get('distribution_data')\n",
    "            \n",
    "            self._add_message(\n",
    "                answer,\n",
    "                \"assistant\",\n",
    "                map_data=map_data,\n",
    "                distribution_data=distribution_data,\n",
    "                routing_info=routing_info\n",
    "            )\n",
    "            self.status_label.value = \"<span style='color: green;'>✅ Ready</span>\"\n",
    "            \n",
    "        except asyncio.TimeoutError:\n",
    "            self._add_message(\"Request timed out after 3 minutes.\", \"system\")\n",
    "            self.status_label.value = \"<span style='color: red;'>❌ Timeout</span>\"\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            error_msg = f\"Error: {str(e)}\\n\\n{traceback.format_exc()}\"\n",
    "            self._add_message(error_msg, \"system\")\n",
    "            self.status_label.value = \"<span style='color: red;'>❌ Error</span>\"\n",
    "        finally:\n",
    "            self.send_button.disabled = False\n",
    "            self.input_box.disabled = False\n",
    "    \n",
    "    def on_clear_clicked(self, button):\n",
    "        \"\"\"Clear chat history.\"\"\"\n",
    "        self.messages_container = []\n",
    "        self.output_area.children = tuple(self.messages_container)\n",
    "        self._add_message(\n",
    "            \"Chat cleared. Ask about California landscape metrics or general data!\",\n",
    "            \"system\"\n",
    "        )\n",
    "    \n",
    "    def on_history_clicked(self, button):\n",
    "        \"\"\"Show conversation history summary.\"\"\"\n",
    "        history = self.system.get_history_summary()\n",
    "        self._add_message(f\"**Conversation History:**\\n\\n{history}\", \"system\")\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the interface.\"\"\"\n",
    "        clear_output(wait=True)\n",
    "        display(HTML(\"\"\"\n",
    "        <style>\n",
    "            .jp-Cell-outputArea { max-height: none !important; }\n",
    "            .output_scroll { max-height: none !important; overflow-y: visible !important; }\n",
    "        </style>\n",
    "        \"\"\"))\n",
    "        display(self.interface)\n",
    "\n",
    "\n",
    "# Create and display the chat interface\n",
    "chat = CoordinatedChatInterface(coordinated_system)\n",
    "chat.display()\n",
    "\n",
    "print(\"✓ Chat interface ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e69c7-3ccc-467d-8dd1-88c8036a29e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
