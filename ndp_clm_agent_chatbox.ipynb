{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Landscape Metrics Analysis - Interactive Chat Interface\n",
    "\n",
    "This notebook offers an interactive chatbox interface that allows users to query the California Landscape Metrics datasets using the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (8.1.7)\n",
      "Requirement already satisfied: pydantic-ai in /home/jovyan/.local/lib/python3.10/site-packages (1.5.0)\n",
      "Requirement already satisfied: fastmcp in /home/jovyan/.local/lib/python3.10/site-packages (2.12.5)\n",
      "Requirement already satisfied: openai in /home/jovyan/.local/lib/python3.10/site-packages (2.6.1)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (8.37.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: pydantic-ai-slim==1.5.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.5.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.3.0)\n",
      "Requirement already satisfied: genai-prices>=0.0.35 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.0.35)\n",
      "Requirement already satisfied: griffe>=1.3.2 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.14.0)\n",
      "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.28.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.38.0)\n",
      "Requirement already satisfied: pydantic-graph==1.5.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.5.0)\n",
      "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (2.12.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.4.2)\n",
      "Requirement already satisfied: temporalio==1.18.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.18.0)\n",
      "Requirement already satisfied: argcomplete>=3.5.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (3.6.3)\n",
      "Requirement already satisfied: prompt-toolkit>=3 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (3.0.52)\n",
      "Requirement already satisfied: pyperclip>=1.9.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.11.0)\n",
      "Requirement already satisfied: rich>=13 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (14.2.0)\n",
      "Requirement already satisfied: mistralai>=1.9.10 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.9.11)\n",
      "Requirement already satisfied: logfire>=3.14.1 in /home/jovyan/.local/lib/python3.10/site-packages (from logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (4.14.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (9.1.2)\n",
      "Requirement already satisfied: google-auth>=2.36.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (2.41.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (2.32.5)\n",
      "Requirement already satisfied: cohere>=5.18.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (5.19.0)\n",
      "Requirement already satisfied: ag-ui-protocol>=0.1.8 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.1.9)\n",
      "Requirement already satisfied: starlette>=0.45.3 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.48.0)\n",
      "Requirement already satisfied: google-genai>=1.46.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.46.0)\n",
      "Collecting mcp>=1.12.3 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai)\n",
      "  Using cached mcp-1.19.0-py3-none-any.whl.metadata (85 kB)\n",
      "Requirement already satisfied: anthropic>=0.70.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.71.0)\n",
      "Requirement already satisfied: boto3>=1.39.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.40.58)\n",
      "Requirement already satisfied: groq>=0.25.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.33.0)\n",
      "Requirement already satisfied: pydantic-evals==1.5.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.5 in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.36.0)\n",
      "Requirement already satisfied: anyio>=0 in /usr/local/lib/python3.10/dist-packages (from pydantic-evals==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (4.11.0)\n",
      "Requirement already satisfied: logfire-api>=3.14.1 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic-evals==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (4.14.1)\n",
      "Requirement already satisfied: pyyaml>=6.0.2 in /usr/local/lib/python3.10/dist-packages (from pydantic-evals==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (6.0.3)\n",
      "Requirement already satisfied: nexus-rpc==1.1.0 in /home/jovyan/.local/lib/python3.10/site-packages (from temporalio==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.1.0)\n",
      "Requirement already satisfied: protobuf<7.0.0,>=3.20 in /home/jovyan/.local/lib/python3.10/site-packages (from temporalio==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (6.33.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from temporalio==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: types-protobuf>=3.20 in /home/jovyan/.local/lib/python3.10/site-packages (from temporalio==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (6.32.1.20250918)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from temporalio==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (4.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.8.2->temporalio==1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.17.0)\n",
      "Requirement already satisfied: authlib>=1.5.2 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (1.6.5)\n",
      "Requirement already satisfied: cyclopts>=3.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (4.0.0)\n",
      "  Using cached mcp-1.16.0-py3-none-any.whl.metadata (80 kB)\n",
      "Requirement already satisfied: openapi-core>=0.19.5 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (0.19.5)\n",
      "Requirement already satisfied: openapi-pydantic>=0.5.1 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (0.5.1)\n",
      "Requirement already satisfied: python-dotenv>=1.1.0 in /home/jovyan/.local/lib/python3.10/site-packages (from fastmcp) (1.1.1)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /home/jovyan/.local/lib/python3.10/site-packages (from mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.4.0)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.10/dist-packages (from mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /home/jovyan/.local/lib/python3.10/site-packages (from mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (2.11.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/jovyan/.local/lib/python3.10/site-packages (from mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /home/jovyan/.local/lib/python3.10/site-packages (from mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (3.0.2)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /home/jovyan/.local/lib/python3.10/site-packages (from mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.38.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (2.41.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/jovyan/.local/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/jovyan/.local/lib/python3.10/site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/jovyan/.local/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio>=0->pydantic-evals==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27->pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27->pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27->pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.16.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.15 in /home/jovyan/.local/lib/python3.10/site-packages (from anthropic>=0.70.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.17.0)\n",
      "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from authlib>=1.5.2->fastmcp) (46.0.2)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.58 in /home/jovyan/.local/lib/python3.10/site-packages (from boto3>=1.39.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.40.58)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/jovyan/.local/lib/python3.10/site-packages (from boto3>=1.39.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /home/jovyan/.local/lib/python3.10/site-packages (from boto3>=1.39.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.14.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.41.0,>=1.40.58->boto3>=1.39.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (2.5.0)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /home/jovyan/.local/lib/python3.10/site-packages (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.12.1)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /home/jovyan/.local/lib/python3.10/site-packages (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.22.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (2.32.4.20250913)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (3.4.3)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (25.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.1.10)\n",
      "Requirement already satisfied: attrs>=23.1.0 in /usr/local/lib/python3.10/dist-packages (from cyclopts>=3.0.0->fastmcp) (25.4.0)\n",
      "Requirement already satisfied: rich-rst<2.0.0,>=1.3.1 in /home/jovyan/.local/lib/python3.10/site-packages (from cyclopts>=3.0.0->fastmcp) (1.3.2)\n",
      "Requirement already satisfied: tomli>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cyclopts>=3.0.0->fastmcp) (2.3.0)\n",
      "Requirement already satisfied: docutils in /home/jovyan/.local/lib/python3.10/site-packages (from rich-rst<2.0.0,>=1.3.1->cyclopts>=3.0.0->fastmcp) (0.22.2)\n",
      "Requirement already satisfied: eval-type-backport>=0.2 in /home/jovyan/.local/lib/python3.10/site-packages (from genai-prices>=0.0.35->pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.2.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/jovyan/.local/lib/python3.10/site-packages (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/jovyan/.local/lib/python3.10/site-packages (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/jovyan/.local/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.6.1)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from google-genai>=1.46.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (15.0.1)\n",
      "Requirement already satisfied: colorama>=0.4 in /home/jovyan/.local/lib/python3.10/site-packages (from griffe>=1.3.2->pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.4.6)\n",
      "Requirement already satisfied: aiohttp in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (3.13.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit>=3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.20.0->mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.20.0->mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.20.0->mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.27.1)\n",
      "Requirement already satisfied: executing>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (2.2.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<1.39.0,>=1.35.0 in /home/jovyan/.local/lib/python3.10/site-packages (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation>=0.41b0 in /home/jovyan/.local/lib/python3.10/site-packages (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.59b0)\n",
      "Requirement already satisfied: opentelemetry-sdk<1.39.0,>=1.35.0 in /home/jovyan/.local/lib/python3.10/site-packages (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.38.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<1.39.0,>=1.35.0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.71.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<1.39.0,>=1.35.0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.38.0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<1.39.0,>=1.35.0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.38.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/jovyan/.local/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.28.0->pydantic-ai-slim==1.5.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-sdk<1.39.0,>=1.35.0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.59b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-httpx>=0.42b0 in /home/jovyan/.local/lib/python3.10/site-packages (from logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.59b0)\n",
      "Requirement already satisfied: invoke<3.0.0,>=2.2.0 in /home/jovyan/.local/lib/python3.10/site-packages (from mistralai>=1.9.10->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (2.2.1)\n",
      "Requirement already satisfied: isodate in /home/jovyan/.local/lib/python3.10/site-packages (from openapi-core>=0.19.5->fastmcp) (0.7.2)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in /home/jovyan/.local/lib/python3.10/site-packages (from openapi-core>=0.19.5->fastmcp) (0.3.4)\n",
      "Requirement already satisfied: more-itertools in /home/jovyan/.local/lib/python3.10/site-packages (from openapi-core>=0.19.5->fastmcp) (10.8.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in /home/jovyan/.local/lib/python3.10/site-packages (from openapi-core>=0.19.5->fastmcp) (0.6.3)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in /home/jovyan/.local/lib/python3.10/site-packages (from openapi-core>=0.19.5->fastmcp) (0.7.2)\n",
      "Requirement already satisfied: parse in /home/jovyan/.local/lib/python3.10/site-packages (from openapi-core>=0.19.5->fastmcp) (1.20.2)\n",
      "Requirement already satisfied: werkzeug<3.1.2 in /home/jovyan/.local/lib/python3.10/site-packages (from openapi-core>=0.19.5->fastmcp) (3.1.1)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in /home/jovyan/.local/lib/python3.10/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi-core>=0.19.5->fastmcp) (0.4.4)\n",
      "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.10/dist-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi-core>=0.19.5->fastmcp) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in /home/jovyan/.local/lib/python3.10/site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi-core>=0.19.5->fastmcp) (1.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug<3.1.2->openapi-core>=0.19.5->fastmcp) (3.0.3)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation>=0.41b0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.17.3)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.59b0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation-httpx>=0.42b0->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.59b0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic[email]>=2.11.7->fastmcp) (2.3.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp) (2.8.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jovyan/.local/lib/python3.10/site-packages (from rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jovyan/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.1.2)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.31.1->mcp>=1.12.3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (8.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/jovyan/.local/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/jovyan/.local/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/jovyan/.local/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jovyan/.local/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jovyan/.local/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/jovyan/.local/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/jovyan/.local/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,vertexai]==1.5.0->pydantic-ai) (1.22.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cryptography->authlib>=1.5.2->fastmcp) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=2.0.0->cryptography->authlib>=1.5.2->fastmcp) (2.23)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Using cached mcp-1.16.0-py3-none-any.whl (167 kB)\n",
      "Installing collected packages: mcp\n",
      "  Attempting uninstall: mcp\n",
      "    Found existing installation: mcp 1.6.0\n",
      "    Uninstalling mcp-1.6.0:\n",
      "      Successfully uninstalled mcp-1.6.0\n",
      "\u001b[33m  WARNING: The script mcp is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "geoserver-mcp 0.3.0 requires mcp==1.6.0, but you have mcp 1.16.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed mcp-1.16.0\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if needed\n",
    "!pip install ipywidgets pydantic-ai fastmcp openai nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import nest_asyncio\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from fastmcp import Client\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "# Enable nested asyncio for Jupyter\n",
    "nest_asyncio.apply()\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration set\n"
     ]
    }
   ],
   "source": [
    "# Base configuration for GeoServer\n",
    "BASE_CONFIG = {\n",
    "    \"wcs_base_url\": \"https://sparcal.sdsc.edu/geoserver\",\n",
    "    \"wfs_base_url\": \"https://sparcal.sdsc.edu/geoserver/boundary/wfs\",\n",
    "    \"feature_id\": \"boundary:ca_counties\",\n",
    "    \"filter_column\": \"name\"\n",
    "}\n",
    "\n",
    "# Initialize MCP client\n",
    "mcp_client = Client(\"https://wenokn.fastmcp.app/mcp\")\n",
    "print(\"✓ Configuration set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using OpenAI GPT-4o-mini\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load variables from .env file into environment\n",
    "load_dotenv()\n",
    "\n",
    "# Set your OpenAI API key\n",
    "# os.environ['OPENAI_API_KEY'] = 'Your API KEY'\n",
    "\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    print(\"⚠️ Warning: OPENAI_API_KEY not set!\")\n",
    "    print(\"Please set it using: os.environ['OPENAI_API_KEY'] = 'your-key'\")\n",
    "else:\n",
    "    print(\"✓ Using OpenAI GPT-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, List\n",
    "import asyncio\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from fastmcp import Client\n",
    "import os\n",
    "\n",
    "@dataclass\n",
    "class AgentContext:\n",
    "    \"\"\"Context to store discovered dataset information.\"\"\"\n",
    "    current_coverage_id: Optional[str] = None\n",
    "    current_dataset_info: Optional[dict] = None\n",
    "\n",
    "# Assuming mcp_client is defined elsewhere, e.g.:\n",
    "# mcp_client = Client(\"https://wenokn.fastmcp.app/mcp\")\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"wcs_base_url\": \"https://sparcal.sdsc.edu/geoserver\",\n",
    "    \"wfs_base_url\": \"https://sparcal.sdsc.edu/geoserver/boundary/wfs\",\n",
    "    \"feature_id\": \"boundary:ca_counties\",\n",
    "    \"filter_column\": \"name\"\n",
    "}\n",
    "\n",
    "def create_internal_agent():\n",
    "    \"\"\"Create and configure the Pydantic AI agent.\"\"\"\n",
    "    \n",
    "    agent = Agent(\n",
    "        model='openai:gpt-4o-mini',\n",
    "        deps_type=AgentContext,\n",
    "        retries=2,\n",
    "        system_prompt=\"\"\"You are an expert in analyzing California Landscape Metrics datasets.\n",
    "\n",
    "The input you receive will be the full conversation history in the format:\n",
    "User: <question1>\n",
    "Assistant: <answer1>\n",
    "User: <question2>\n",
    "Assistant: <answer2>\n",
    "...\n",
    "User: <current question>\n",
    "\n",
    "Use this history to understand the context for follow-up questions.\n",
    "\n",
    "You have access to these tools:\n",
    "1. search_and_select_dataset: Search for the most relevant dataset based on the question\n",
    "2. get_county_statistics: Compute statistics for one or more counties\n",
    "3. get_area_above_threshold: Calculate percentage/area above a threshold for one or more counties\n",
    "4. get_area_below_threshold: Calculate percentage/area below a threshold for one or more counties\n",
    "5. show_map: Display a map visualization of the current dataset\n",
    "\n",
    "**CRITICAL RULE FOR SEARCH:**\n",
    "When calling search_and_select_dataset, construct a search query that represents the current user's question.\n",
    "If the current question is a follow-up (e.g., \"How about San Diego?\"), incorporate context from the history to make it a standalone query (e.g., \"What is the average carbon turnover time in San Diego?\").\n",
    "DO NOT pass vague follow-up phrases directly; always create a meaningful, context-aware query.\n",
    "DO NOT use the entire history as the query.\n",
    "When calling search_and_select_dataset, please remove the terms related to statistics like \"average\" and \"mean\" and the place names from the question like 'San Diego' or 'Los Angeles'. \n",
    "For example, for the question \"What is the average carbon turnover time in Los Angeles?\", use \"carbon turnover time\" to call search_and_select_dataset.\n",
    "\n",
    "**WORKFLOW:**\n",
    "1. If needed, start by calling search_and_select_dataset with the constructed query.\n",
    "   - If a similar dataset was used in previous interactions (based on history), you may skip searching if it's clearly the same topic.\n",
    "2. Once the dataset is selected, use the other tools to answer the question.\n",
    "3. Include the dataset name and units in your final answer for context.\n",
    "\n",
    "**For statistical questions:**\n",
    "- Use get_county_statistics for mean, median, min, max, std\n",
    "- Pass counties=None to get all counties\n",
    "- For rankings, get all counties and sort results\n",
    "\n",
    "**For threshold questions:**\n",
    "- Use get_area_above_threshold or get_area_below_threshold\n",
    "- Pass counties=None to get all counties\n",
    "- For questions about many/all counties, you can use counties=None, but if concerned about timeouts, first get list of counties from get_county_statistics and sample 10-20\n",
    "\n",
    "**For map visualization requests:**\n",
    "- When users ask to \"show the map\", \"visualize\", \"display map\", or similar requests, use the show_map tool\n",
    "- You must have a dataset selected first (via search_and_select_dataset)\n",
    "- The tool will return a special marker that the interface will use to render the map\n",
    "\n",
    "**Answer format:**\n",
    "- Be precise with numbers and include units from the dataset\n",
    "- Provide clear, concise answers\n",
    "- Mention the dataset being used\n",
    "\"\"\",\n",
    "    )\n",
    "\n",
    "    @agent.tool\n",
    "    async def search_and_select_dataset(\n",
    "        ctx: RunContext[AgentContext],\n",
    "        question: str,\n",
    "        top_k: int = 3\n",
    "    ) -> dict:\n",
    "        \"\"\"Search for and select the most relevant dataset.\"\"\"\n",
    "        async with mcp_client:\n",
    "            result = await mcp_client.call_tool(\n",
    "                \"search_datasets\",\n",
    "                {\"query\": question, \"top_k\": top_k}\n",
    "            )\n",
    "            \n",
    "            data = result.data\n",
    "            if data.get('success') and data.get('datasets'):\n",
    "                best_dataset = data['datasets'][0]\n",
    "                ctx.deps.current_coverage_id = best_dataset['wcs_coverage_id']\n",
    "                ctx.deps.current_dataset_info = best_dataset\n",
    "                \n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'selected_dataset': best_dataset,\n",
    "                    'alternatives': data['datasets'][1:] if len(data['datasets']) > 1 else [],\n",
    "                    'message': f\"Selected: {best_dataset['title']}\"\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'success': False,\n",
    "                    'message': 'No suitable datasets found',\n",
    "                    'error': data.get('error', 'Unknown error')\n",
    "                }\n",
    "\n",
    "    @agent.tool\n",
    "    async def get_county_statistics(\n",
    "        ctx: RunContext[AgentContext],\n",
    "        counties: Optional[List[str]] = None,\n",
    "        stats: List[str] = None\n",
    "    ) -> dict:\n",
    "        \"\"\"Get statistics for one or more counties.\"\"\"\n",
    "        if not ctx.deps.current_coverage_id:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': 'No dataset selected. Call search_and_select_dataset first.'\n",
    "            }\n",
    "        \n",
    "        if stats is None:\n",
    "            stats = [\"mean\", \"median\", \"min\", \"max\", \"std\"]\n",
    "        \n",
    "        async with mcp_client:\n",
    "            result = await mcp_client.call_tool(\n",
    "                \"compute_zonal_stats\",\n",
    "                {\n",
    "                    **BASE_CONFIG,\n",
    "                    \"wcs_coverage_id\": ctx.deps.current_coverage_id,\n",
    "                    \"filter_value\": counties,\n",
    "                    \"stats\": stats,\n",
    "                    \"max_workers\": 16\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            response = result.data\n",
    "            if response.get('success'):\n",
    "                response['dataset_info'] = {\n",
    "                    'title': ctx.deps.current_dataset_info.get('title'),\n",
    "                    'units': ctx.deps.current_dataset_info.get('data_units')\n",
    "                }\n",
    "            return response\n",
    "\n",
    "    @agent.tool\n",
    "    async def get_area_above_threshold(\n",
    "        ctx: RunContext[AgentContext],\n",
    "        counties: Optional[List[str]] = None,\n",
    "        threshold: float = 100.0\n",
    "    ) -> dict:\n",
    "        \"\"\"Calculate the percentage and area above a threshold for one or more counties.\"\"\"\n",
    "        if not ctx.deps.current_coverage_id:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': 'No dataset selected. Call search_and_select_dataset first.'\n",
    "            }\n",
    "        \n",
    "        async with mcp_client:\n",
    "            result = await mcp_client.call_tool(\n",
    "                \"zonal_count\",\n",
    "                {\n",
    "                    **BASE_CONFIG,\n",
    "                    \"wcs_coverage_id\": ctx.deps.current_coverage_id,\n",
    "                    \"filter_value\": counties,\n",
    "                    \"threshold\": threshold,\n",
    "                    \"max_workers\": 16\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            zonal_data = result.data\n",
    "            if not zonal_data.get('success'):\n",
    "                return zonal_data\n",
    "            \n",
    "            processed = []\n",
    "            for stats in zonal_data['data']:\n",
    "                county_name = stats[BASE_CONFIG['filter_column']]\n",
    "                valid = stats['valid_pixels']\n",
    "                above = stats['above_threshold_pixels']\n",
    "                pixel_area = stats['pixel_area_square_meters']\n",
    "                \n",
    "                percentage = (above / valid * 100) if valid > 0 else 0\n",
    "                area_sq_m = above * pixel_area\n",
    "                area_sq_km = area_sq_m / 1_000_000\n",
    "                \n",
    "                processed.append({\n",
    "                    'county': county_name,\n",
    "                    'threshold': threshold,\n",
    "                    'valid_pixels': valid,\n",
    "                    'above_threshold_pixels': above,\n",
    "                    'percentage': percentage,\n",
    "                    'area_square_meters': area_sq_m,\n",
    "                    'area_square_km': area_sq_km\n",
    "                })\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'data': processed,\n",
    "                'total_features': zonal_data['total_features'],\n",
    "                'processed_features': zonal_data['processed_features'],\n",
    "                'dataset_info': {\n",
    "                    'title': ctx.deps.current_dataset_info.get('title'),\n",
    "                    'units': ctx.deps.current_dataset_info.get('data_units')\n",
    "                }\n",
    "            }\n",
    "\n",
    "    @agent.tool\n",
    "    async def get_area_below_threshold(\n",
    "        ctx: RunContext[AgentContext],\n",
    "        counties: Optional[List[str]] = None,\n",
    "        threshold: float = 100.0\n",
    "    ) -> dict:\n",
    "        \"\"\"Calculate the percentage and area below a threshold for one or more counties.\"\"\"\n",
    "        if not ctx.deps.current_coverage_id:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': 'No dataset selected. Call search_and_select_dataset first.'\n",
    "            }\n",
    "        \n",
    "        async with mcp_client:\n",
    "            result = await mcp_client.call_tool(\n",
    "                \"zonal_count\",\n",
    "                {\n",
    "                    **BASE_CONFIG,\n",
    "                    \"wcs_coverage_id\": ctx.deps.current_coverage_id,\n",
    "                    \"filter_value\": counties,\n",
    "                    \"threshold\": threshold,\n",
    "                    \"max_workers\": 16\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            zonal_data = result.data\n",
    "            if not zonal_data.get('success'):\n",
    "                return zonal_data\n",
    "            \n",
    "            processed = []\n",
    "            for stats in zonal_data['data']:\n",
    "                county_name = stats[BASE_CONFIG['filter_column']]\n",
    "                valid = stats['valid_pixels']\n",
    "                above = stats['above_threshold_pixels']\n",
    "                below = valid - above\n",
    "                pixel_area = stats['pixel_area_square_meters']\n",
    "                \n",
    "                percentage = (below / valid * 100) if valid > 0 else 0\n",
    "                area_sq_m = below * pixel_area\n",
    "                area_sq_km = area_sq_m / 1_000_000\n",
    "                \n",
    "                processed.append({\n",
    "                    'county': county_name,\n",
    "                    'threshold': threshold,\n",
    "                    'valid_pixels': valid,\n",
    "                    'below_threshold_pixels': below,\n",
    "                    'percentage': percentage,\n",
    "                    'area_square_meters': area_sq_m,\n",
    "                    'area_square_km': area_sq_km\n",
    "                })\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'data': processed,\n",
    "                'total_features': zonal_data['total_features'],\n",
    "                'processed_features': zonal_data['processed_features'],\n",
    "                'dataset_info': {\n",
    "                    'title': ctx.deps.current_dataset_info.get('title'),\n",
    "                    'units': ctx.deps.current_dataset_info.get('data_units')\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    @agent.tool\n",
    "    async def show_map(ctx: RunContext[AgentContext]) -> dict:\n",
    "        \"\"\"Display a map visualization of the current dataset using WMS layer.\"\"\"\n",
    "        if not ctx.deps.current_dataset_info:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': 'No dataset selected. Call search_and_select_dataset first.'\n",
    "            }\n",
    "        \n",
    "        dataset = ctx.deps.current_dataset_info\n",
    "        \n",
    "        # Return map configuration that the interface will use to render\n",
    "        return {\n",
    "            'success': True,\n",
    "            'action': 'show_map',\n",
    "            'map_data': {\n",
    "                'wms_base_url': dataset.get('wms_base_url'),\n",
    "                'wms_layer_name': dataset.get('wms_layer_name'),\n",
    "                'title': dataset.get('title'),\n",
    "                'description': dataset.get('description', ''),\n",
    "                'units': dataset.get('data_units', '')\n",
    "            },\n",
    "            'message': f\"Displaying map for: {dataset.get('title')}\"\n",
    "        }\n",
    "    \n",
    "    return agent\n",
    "\n",
    "class HistoryAwareAgent:\n",
    "    def __init__(self):\n",
    "        self.internal_agent = create_internal_agent()\n",
    "        self.history = []\n",
    "\n",
    "    async def run(self, question: str, timeout: int = 300, deps: Optional[AgentContext] = None) -> dict:\n",
    "        \"\"\"Run the agent with history-aware input. Returns dict with output and optional map_data.\"\"\"\n",
    "        # Build the full input with history\n",
    "        full_input = \"\\n\".join(self.history) + (f\"\\nUser: {question}\" if self.history else f\"User: {question}\")\n",
    "\n",
    "        try:\n",
    "            # Pass deps to internal agent's run method\n",
    "            result = await asyncio.wait_for(\n",
    "                self.internal_agent.run(full_input, deps=deps),\n",
    "                timeout=timeout\n",
    "            )\n",
    "            output = result.output if hasattr(result, 'output') else str(result)\n",
    "            \n",
    "            # Check if any tool result contains map data\n",
    "            map_data = None\n",
    "            if hasattr(result, 'all_messages'):\n",
    "                for msg in result.all_messages():\n",
    "                    if hasattr(msg, 'parts'):\n",
    "                        for part in msg.parts:\n",
    "                            if hasattr(part, 'content') and isinstance(part.content, dict):\n",
    "                                if part.content.get('action') == 'show_map':\n",
    "                                    map_data = part.content.get('map_data')\n",
    "\n",
    "            # Append to history\n",
    "            self.history.append(f\"User: {question}\")\n",
    "            self.history.append(f\"Assistant: {output}\")\n",
    "\n",
    "            return {\n",
    "                'output': output,\n",
    "                'map_data': map_data\n",
    "            }\n",
    "        except asyncio.TimeoutError:\n",
    "            return {\n",
    "                'output': f\"Error: Question timed out after {timeout} seconds. This query may be too complex.\",\n",
    "                'map_data': None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'output': f\"Error: {type(e).__name__}: {str(e)[:200]}\",\n",
    "                'map_data': None\n",
    "            }\n",
    "\n",
    "# Create the agent\n",
    "agent = HistoryAwareAgent()\n",
    "print(\"✓ Agent created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Javascript, display, clear_output, HTML\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime\n",
    "import folium\n",
    "from folium import WmsTileLayer\n",
    "import json\n",
    "\n",
    "class ChatInterface:\n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "        self.messages_container = []\n",
    "        \n",
    "        # Output area that takes available space\n",
    "        self.output_area = widgets.VBox(\n",
    "            layout=widgets.Layout(\n",
    "                border='1px solid #ddd',\n",
    "                height='calc(100vh - 350px)',  # Dynamic height based on viewport\n",
    "                min_height='400px',\n",
    "                overflow_y='auto',\n",
    "                padding='10px',\n",
    "                margin='0 0 10px 0'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.input_box = widgets.Textarea(\n",
    "            placeholder='Ask a question about California Landscape Metrics...',\n",
    "            layout=widgets.Layout(width='100%', height='100px', margin='10px 0')\n",
    "        )\n",
    "        \n",
    "        self.send_button = widgets.Button(\n",
    "            description='Send',\n",
    "            button_style='primary',\n",
    "            icon='paper-plane',\n",
    "            layout=widgets.Layout(width='100px', margin='0 5px 0 0')\n",
    "        )\n",
    "        \n",
    "        self.clear_button = widgets.Button(\n",
    "            description='Clear',\n",
    "            button_style='warning',\n",
    "            icon='trash',\n",
    "            layout=widgets.Layout(width='100px', margin='0 5px 0 0')\n",
    "        )\n",
    "        \n",
    "        self.status_label = widgets.HTML(\n",
    "            value=\"✅ Ready\",\n",
    "            layout=widgets.Layout(margin='0 0 0 10px')\n",
    "        )\n",
    "        \n",
    "        # Add button click handlers\n",
    "        self.send_button.on_click(self.on_send_clicked)\n",
    "        self.clear_button.on_click(self.on_clear_clicked)\n",
    "        \n",
    "        button_box = widgets.HBox([\n",
    "            self.send_button, \n",
    "            self.clear_button, \n",
    "            self.status_label\n",
    "        ])\n",
    "        \n",
    "        self.interface = widgets.VBox([\n",
    "            widgets.HTML(value=\"<h3>🌲 California Landscape Metrics Chat</h3>\"),\n",
    "            self.output_area,\n",
    "            self.input_box,\n",
    "            button_box\n",
    "        ], layout=widgets.Layout(width='100%', max_width='1200px', margin='0 auto'))\n",
    "        \n",
    "        # Add welcome message\n",
    "        self._add_message(\n",
    "            \"Welcome! Ask me about California landscape metrics.\\n\\n\"\n",
    "            \"Examples:\\n\"\n",
    "            \"- What is the average carbon turnover time in Los Angeles?\\n\"\n",
    "            \"- Find the maximum annual burn probability in San Diego county\\n\"\n",
    "            \"- Show me a map of the carbon turnover dataset\",\n",
    "            \"system\"\n",
    "        )\n",
    "    \n",
    "    def _get_wms_bounds(self, wms_url, layer_name):\n",
    "        \"\"\"Try to get WMS layer bounds from GetCapabilities. Returns California bounds as fallback.\"\"\"\n",
    "        # Default California bounds [south, west, north, east]\n",
    "        california_bounds = [[32.5, -124.5], [42.0, -114.0]]\n",
    "        \n",
    "        try:\n",
    "            import requests\n",
    "            from xml.etree import ElementTree as ET\n",
    "            \n",
    "            # Request GetCapabilities\n",
    "            params = {\n",
    "                'service': 'WMS',\n",
    "                'version': '1.1.0',\n",
    "                'request': 'GetCapabilities'\n",
    "            }\n",
    "            response = requests.get(wms_url + '/wms', params=params, timeout=10)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                root = ET.fromstring(response.content)\n",
    "                # Find the layer\n",
    "                for layer in root.iter('Layer'):\n",
    "                    name_elem = layer.find('Name')\n",
    "                    if name_elem is not None and name_elem.text == layer_name:\n",
    "                        # Get LatLonBoundingBox\n",
    "                        bbox = layer.find('LatLonBoundingBox')\n",
    "                        if bbox is not None:\n",
    "                            minx = float(bbox.get('minx'))\n",
    "                            miny = float(bbox.get('miny'))\n",
    "                            maxx = float(bbox.get('maxx'))\n",
    "                            maxy = float(bbox.get('maxy'))\n",
    "                            return [[miny, minx], [maxy, maxx]]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return california_bounds\n",
    "    \n",
    "    def _get_legend_url(self, wms_url, layer_name, style_name=None):\n",
    "        \"\"\"Generate WMS GetLegendGraphic URL.\"\"\"\n",
    "        from urllib.parse import urlencode\n",
    "        \n",
    "        params = {\n",
    "            'service': 'WMS',\n",
    "            'version': '1.1.0',\n",
    "            'request': 'GetLegendGraphic',\n",
    "            'layer': layer_name,\n",
    "            'format': 'image/png',\n",
    "            'width': '20',\n",
    "            'height': '20',\n",
    "            'legend_options': 'fontAntiAliasing:true;fontSize:10;fontName:Arial;dx:5;absoluteMargins:true'\n",
    "        }\n",
    "        \n",
    "        if style_name:\n",
    "            params['style'] = style_name\n",
    "        \n",
    "        return f\"{wms_url}/wms?{urlencode(params)}\"\n",
    "    \n",
    "    def _create_map(self, map_data, style_name=None):\n",
    "        \"\"\"Create a Folium map with WMS layer.\n",
    "        \n",
    "        Args:\n",
    "            map_data: Dictionary containing WMS layer information\n",
    "            style_name: Optional WMS style name to apply (e.g., 'layer_name_std')\n",
    "        \"\"\"\n",
    "        try:\n",
    "            wms_url = map_data.get('wms_base_url', '')\n",
    "            layer_name = map_data.get('wms_layer_name', '')\n",
    "            title = map_data.get('title', 'Dataset')\n",
    "            \n",
    "            # Get WMS bounds\n",
    "            bounds = self._get_wms_bounds(wms_url, layer_name)\n",
    "            \n",
    "            # Create map centered on bounds\n",
    "            center_lat = (bounds[0][0] + bounds[1][0]) / 2\n",
    "            center_lon = (bounds[0][1] + bounds[1][1]) / 2\n",
    "            \n",
    "            m = folium.Map(\n",
    "                location=[center_lat, center_lon],\n",
    "                tiles='OpenStreetMap',\n",
    "                control_scale=True\n",
    "            )\n",
    "            \n",
    "            # Fit bounds to WMS extent\n",
    "            m.fit_bounds(bounds)\n",
    "            \n",
    "            if wms_url and layer_name:\n",
    "                # Add WMS tile layer with optional style\n",
    "                wms_params = {\n",
    "                    'url': wms_url + '/wms',\n",
    "                    'layers': layer_name,\n",
    "                    'name': title,\n",
    "                    'fmt': 'image/png',\n",
    "                    'transparent': True,\n",
    "                    'overlay': True,\n",
    "                    'control': True,\n",
    "                    'version': '1.1.0'\n",
    "                }\n",
    "                \n",
    "                # Add style if provided\n",
    "                if style_name:\n",
    "                    wms_params['styles'] = style_name\n",
    "                \n",
    "                wms = WmsTileLayer(**wms_params)\n",
    "                wms.add_to(m)\n",
    "                \n",
    "                # Add layer control\n",
    "                folium.LayerControl().add_to(m)\n",
    "                \n",
    "                # Add legend with unit\n",
    "                legend_url = self._get_legend_url(wms_url, layer_name, style_name)\n",
    "                units = map_data.get('units', '')\n",
    "                unit_text = f'<p style=\"margin: 5px 0 0 0; font-size: 11px; color: #333; text-align: center;\">Units: {units}</p>' if units else ''\n",
    "                \n",
    "                legend_html = f'''\n",
    "                <div style=\"position: fixed; \n",
    "                            top: 10px; \n",
    "                            right: 10px; \n",
    "                            background-color: white; \n",
    "                            z-index: 9999; \n",
    "                            padding: 10px; \n",
    "                            border: 2px solid grey;\n",
    "                            border-radius: 5px; \n",
    "                            box-shadow: 2px 2px 6px rgba(0,0,0,0.3);\">\n",
    "                    <img src=\"{legend_url}\" alt=\"Legend\" style=\"display: block;\">\n",
    "                    {unit_text}\n",
    "                </div>\n",
    "                '''\n",
    "                m.get_root().html.add_child(folium.Element(legend_html))\n",
    "            \n",
    "            return m\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating map: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _add_message(self, text, role=\"user\", map_data=None):\n",
    "        \"\"\"Add a message to the chat interface, optionally with a map.\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        if role == \"user\":\n",
    "            color = \"#007bff\"\n",
    "            icon = \"👤\"\n",
    "            label = \"You\"\n",
    "            bg_color = \"#e7f3ff\"\n",
    "        elif role == \"assistant\":\n",
    "            color = \"#28a745\"\n",
    "            icon = \"🤖\"\n",
    "            label = \"Assistant\"\n",
    "            bg_color = \"#e8f5e9\"\n",
    "        else:\n",
    "            color = \"#6c757d\"\n",
    "            icon = \"ℹ️\"\n",
    "            label = \"System\"\n",
    "            bg_color = \"#f8f9fa\"\n",
    "        \n",
    "        # Escape HTML in text content\n",
    "        import html\n",
    "        escaped_text = html.escape(str(text))\n",
    "        \n",
    "        message_html = widgets.HTML(\n",
    "            value=f\"\"\"\n",
    "            <div style='margin: 10px 0; padding: 12px; background-color: {bg_color}; \n",
    "                        border-radius: 8px; border-left: 4px solid {color}; box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n",
    "                        position: relative; z-index: 1;'>\n",
    "                <div style='display: flex; justify-content: space-between; margin-bottom: 8px;'>\n",
    "                    <strong style='color: {color};'>{icon} {label}</strong>\n",
    "                    <span style='color: #999; font-size: 0.85em;'>{timestamp}</span>\n",
    "                </div>\n",
    "                <div style='white-space: pre-wrap; word-wrap: break-word; line-height: 1.5;'>{escaped_text}</div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        self.messages_container.append(message_html)\n",
    "        \n",
    "        # Add map if provided (must be added AFTER the message)\n",
    "        if map_data:\n",
    "            # Optionally append '_std' to the layer name for the style\n",
    "            layer_name = map_data.get('wms_layer_name', '')\n",
    "            style_name = f\"{layer_name}_std\" if layer_name else None\n",
    "            \n",
    "            folium_map = self._create_map(map_data, style_name=style_name)\n",
    "            if folium_map:\n",
    "                # Create a wrapper div to contain and isolate the map\n",
    "                map_html_content = folium_map._repr_html_()\n",
    "                wrapped_html = f\"\"\"\n",
    "                <div style='width: 98%; margin: 10px 0; clear: both;'>\n",
    "                    <div style='width: 100%; height: 300px; border: 1px solid #ddd; border-radius: 8px; overflow: hidden; position: relative;'>\n",
    "                        <div style='width: 100%; height: 100%;'>\n",
    "                            {map_html_content}\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                \n",
    "                map_widget = widgets.HTML(\n",
    "                    value=wrapped_html,\n",
    "                    layout=widgets.Layout(width='100%')\n",
    "                )\n",
    "                self.messages_container.append(map_widget)\n",
    "        \n",
    "        # Update the output area with all messages\n",
    "        self.output_area.children = tuple(self.messages_container)\n",
    "    \n",
    "    def on_send_clicked(self, button):\n",
    "        question = self.input_box.value.strip()\n",
    "        if not question:\n",
    "            return\n",
    "        \n",
    "        self._add_message(question, \"user\")\n",
    "        self.input_box.value = \"\"\n",
    "        self.send_button.disabled = True\n",
    "        self.input_box.disabled = True\n",
    "        self.status_label.value = \"<span style='color: orange;'>⏳ Processing...</span>\"\n",
    "        \n",
    "        try:\n",
    "            ctx = AgentContext()\n",
    "            result = asyncio.get_event_loop().run_until_complete(\n",
    "                asyncio.wait_for(self.agent.run(question, deps=ctx), timeout=180)\n",
    "            )\n",
    "            \n",
    "            # Handle both old string format and new dict format\n",
    "            if isinstance(result, dict):\n",
    "                answer = result.get('output', str(result))\n",
    "                map_data = result.get('map_data')\n",
    "            else:\n",
    "                answer = result.output if hasattr(result, 'output') else str(result)\n",
    "                map_data = None\n",
    "            \n",
    "            self._add_message(answer, \"assistant\", map_data=map_data)\n",
    "            self.status_label.value = \"<span style='color: green;'>✅ Ready</span>\"\n",
    "            \n",
    "        except asyncio.TimeoutError:\n",
    "            error_msg = \"Request timed out after 3 minutes. Please try a simpler question or try again.\"\n",
    "            self._add_message(error_msg, \"system\")\n",
    "            self.status_label.value = \"<span style='color: red;'>❌ Timeout</span>\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            error_msg = f\"Error: {str(e)}\\n\\n{traceback.format_exc()}\"\n",
    "            self._add_message(error_msg, \"system\")\n",
    "            self.status_label.value = \"<span style='color: red;'>❌ Error</span>\"\n",
    "        \n",
    "        finally:\n",
    "            self.send_button.disabled = False\n",
    "            self.input_box.disabled = False\n",
    "    \n",
    "    def on_clear_clicked(self, button):\n",
    "        self.messages_container = []\n",
    "        self.output_area.children = tuple(self.messages_container)\n",
    "        self._add_message(\n",
    "            \"Chat cleared. Ready for new questions!\\n\\n\"\n",
    "            \"Examples:\\n\"\n",
    "            \"- What is the average carbon turnover time in Los Angeles?\\n\"\n",
    "            \"- Find the maximum annual burn probability in San Diego county\\n\"\n",
    "            \"- Show me a map of the carbon turnover dataset\",\n",
    "            \"system\"\n",
    "        )\n",
    "    \n",
    "    def display(self):\n",
    "        # Clear any previous output in the cell\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Display the interface\n",
    "        display(HTML(\"\"\"\n",
    "        <style>\n",
    "            /* Make the cell output area expand */\n",
    "            .jp-Cell-outputArea {\n",
    "                max-height: none !important;\n",
    "            }\n",
    "            .output_scroll {\n",
    "                max-height: none !important;\n",
    "                overflow-y: visible !important;\n",
    "            }\n",
    "        </style>\n",
    "        \"\"\"))\n",
    "        \n",
    "        display(self.interface)\n",
    "\n",
    "\n",
    "# Create and display chat interface\n",
    "chat = ChatInterface(agent)\n",
    "chat.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Questions\n",
    "\n",
    "1. Find the maximum annual burn probability in San Diego county.\n",
    "2. Could you do the same for Orange county?\n",
    "3. Los Angeles, Please!\n",
    "4. Show me a map of the annual burn probability dataset.\n",
    "5. Which county has higher annual burn probability, San Diego or Los Angeles?\n",
    "6. What percentage of area in San Diego County has carbon turnover time above 100 years?\n",
    "7. Rank the top 5 counties by mean carbon turnover time.\n",
    "8. Show all counties where at least 30% of the total area has a carbon turnover time of less than 20 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
